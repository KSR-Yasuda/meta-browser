From 4a944b24870f560b1464fc14310c319484b112b9 Mon Sep 17 00:00:00 2001
From: Takuro Ashie <ashie@homa.ne.jp>
Date: Fri, 7 Oct 2016 19:49:44 +0900
Subject: [PATCH 1/3] Backport dom/media/platforms/omx from mozilla-central to
 ESR45

It's needed to supprot video decoding.
The code is taken from:

  gecko-dev:f6ee6d53f22d75c7924a57f7c329914a21af3c86

then resolve compile errors. But this commit doesn't address
compile errors of GonkOmxPlatformLayer because gecko-embedded
project doesn't use Gonk at this moment.

Signed-off-by: Takuro Ashie <ashie@homa.ne.jp>
---
 dom/media/platforms/omx/GonkOmxPlatformLayer.cpp | 468 +++++++++++++++---
 dom/media/platforms/omx/GonkOmxPlatformLayer.h   | 120 ++++-
 dom/media/platforms/omx/OmxDataDecoder.cpp       | 578 +++++++++++++++--------
 dom/media/platforms/omx/OmxDataDecoder.h         |  54 ++-
 dom/media/platforms/omx/OmxDecoderModule.cpp     |  21 +-
 dom/media/platforms/omx/OmxDecoderModule.h       |   2 -
 dom/media/platforms/omx/OmxPlatformLayer.cpp     | 329 +++++++++++++
 dom/media/platforms/omx/OmxPlatformLayer.h       |  39 +-
 dom/media/platforms/omx/OmxPromiseLayer.cpp      | 159 ++++---
 dom/media/platforms/omx/OmxPromiseLayer.h        |  53 ++-
 dom/media/platforms/omx/moz.build                |   6 +-
 11 files changed, 1432 insertions(+), 397 deletions(-)
 create mode 100644 dom/media/platforms/omx/OmxPlatformLayer.cpp

diff --git a/dom/media/platforms/omx/GonkOmxPlatformLayer.cpp b/dom/media/platforms/omx/GonkOmxPlatformLayer.cpp
index c6b9e43..363abe8 100644
--- a/dom/media/platforms/omx/GonkOmxPlatformLayer.cpp
+++ b/dom/media/platforms/omx/GonkOmxPlatformLayer.cpp
@@ -4,34 +4,59 @@
  * License, v. 2.0. If a copy of the MPL was not distributed with this
  * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
 
-#include "OmxDataDecoder.h"
-#include "OmxPromiseLayer.h"
 #include "GonkOmxPlatformLayer.h"
-#include "MediaInfo.h"
+
 #include <binder/MemoryDealer.h>
+#include <cutils/properties.h>
 #include <media/IOMX.h>
+#include <media/stagefright/MediaCodecList.h>
 #include <utils/List.h>
-#include <media/stagefright/OMXCodec.h>
 
-extern mozilla::LogModule* GetPDMLog();
+#include "mozilla/Monitor.h"
+#include "mozilla/layers/TextureClient.h"
+#include "mozilla/layers/GrallocTextureClient.h"
+#include "mozilla/layers/ImageBridgeChild.h"
+#include "mozilla/layers/TextureClientRecycleAllocator.h"
+
+#include "ImageContainer.h"
+#include "MediaInfo.h"
+#include "OmxDataDecoder.h"
+
 
 #ifdef LOG
 #undef LOG
 #endif
 
-#define LOG(arg, ...) MOZ_LOG(GetPDMLog(), mozilla::LogLevel::Debug, ("GonkOmxPlatformLayer:: " arg, ##__VA_ARGS__))
+#define LOG(arg, ...) MOZ_LOG(sPDMLog, mozilla::LogLevel::Debug, ("GonkOmxPlatformLayer(%p)::%s: " arg, this, __func__, ##__VA_ARGS__))
+
+#define CHECK_ERR(err)                    \
+  if (err != OK)                       {  \
+    LOG("error %d at %s", err, __func__); \
+    return NS_ERROR_FAILURE;              \
+  }                                       \
+
+// Android proprietary value.
+#define ANDROID_OMX_VIDEO_CodingVP8 (static_cast<OMX_VIDEO_CODINGTYPE>(9))
 
 using namespace android;
 
 namespace mozilla {
 
-extern void GetPortIndex(nsTArray<uint32_t>& aPortIndex);
-
-bool IsSoftwareCodec(const char* aComponentName) {
+// In Gonk, the software component name has prefix "OMX.google". It needs to
+// have a way to use hardware codec first.
+bool IsSoftwareCodec(const char* aComponentName)
+{
   nsAutoCString str(aComponentName);
   return (str.Find(NS_LITERAL_CSTRING("OMX.google.")) == -1 ? false : true);
 }
 
+bool IsInEmulator()
+{
+  char propQemu[PROPERTY_VALUE_MAX];
+  property_get("ro.kernel.qemu", propQemu, "");
+  return !strncmp(propQemu, "1", 1);
+}
+
 class GonkOmxObserver : public BnOMXObserver {
 public:
   void onMessage(const omx_message& aMsg)
@@ -114,32 +139,217 @@ public:
 protected:
   RefPtr<TaskQueue> mTaskQueue;
   // TODO:
-  //   we should combination both event handlers into one. And we should provide
-  //   an unified way for event handling in OmxPlatforLayer class.
+  //   we should combine both event handlers into one. And we should provide
+  //   an unified way for event handling in OmxPlatformLayer class.
   RefPtr<OmxPromiseLayer> mPromiseLayer;
   RefPtr<OmxDataDecoder> mClient;
 };
 
-GonkBufferData::GonkBufferData(android::IOMX::buffer_id aId, bool aLiveInLocal, android::IMemory* aMemory)
-  : BufferData((OMX_BUFFERHEADERTYPE*)aId)
-  , mId(aId)
+// This class allocates Gralloc buffer and manages TextureClient's recycle.
+class GonkTextureClientRecycleHandler : public layers::ITextureClientRecycleAllocator
+{
+  typedef MozPromise<layers::TextureClient*, nsresult, /* IsExclusive = */ true> TextureClientRecyclePromise;
+
+public:
+  GonkTextureClientRecycleHandler(OMX_VIDEO_PORTDEFINITIONTYPE& aDef)
+    : ITextureClientRecycleAllocator()
+    , mMonitor("GonkTextureClientRecycleHandler")
+  {
+    RefPtr<layers::ImageBridgeChild> bridge = layers::ImageBridgeChild::GetSingleton();
+
+    // Allocate Gralloc texture memory.
+    layers::GrallocTextureData* textureData =
+      layers::GrallocTextureData::Create(gfx::IntSize(aDef.nFrameWidth, aDef.nFrameHeight),
+                                         aDef.eColorFormat,
+                                         gfx::BackendType::NONE,
+                                         GraphicBuffer::USAGE_HW_TEXTURE | GraphicBuffer::USAGE_SW_READ_OFTEN,
+                                         bridge);
+
+    mGraphBuffer = textureData->GetGraphicBuffer();
+    MOZ_ASSERT(mGraphBuffer.get());
+
+    mTextureClient =
+      layers::TextureClient::CreateWithData(textureData,
+                                            layers::TextureFlags::DEALLOCATE_CLIENT | layers::TextureFlags::RECYCLE,
+                                            bridge);
+    MOZ_ASSERT(mTextureClient);
+
+    mPromise.SetMonitor(&mMonitor);
+  }
+
+  RefPtr<TextureClientRecyclePromise> WaitforRecycle()
+  {
+    MonitorAutoLock lock(mMonitor);
+    MOZ_ASSERT(!!mGraphBuffer.get());
+
+    mTextureClient->SetRecycleAllocator(this);
+    return mPromise.Ensure(__func__);
+  }
+
+  // DO NOT use smart pointer to receive TextureClient; otherwise it will
+  // distrupt the reference count.
+  layers::TextureClient* GetTextureClient()
+  {
+    return mTextureClient;
+  }
+
+  GraphicBuffer* GetGraphicBuffer()
+  {
+    MonitorAutoLock lock(mMonitor);
+    return mGraphBuffer.get();
+  }
+
+  // This function is called from layers thread.
+  void RecycleTextureClient(layers::TextureClient* aClient) override
+  {
+    MOZ_ASSERT(mTextureClient == aClient);
+
+    // Clearing the recycle allocator drops a reference, so make sure we stay alive
+    // for the duration of this function.
+    RefPtr<GonkTextureClientRecycleHandler> kungFuDeathGrip(this);
+    aClient->SetRecycleAllocator(nullptr);
+
+    {
+      MonitorAutoLock lock(mMonitor);
+      mPromise.ResolveIfExists(mTextureClient, __func__);
+    }
+  }
+
+  void Shutdown()
+  {
+    MonitorAutoLock lock(mMonitor);
+
+    mPromise.RejectIfExists(NS_ERROR_FAILURE, __func__);
+
+    // DO NOT clear TextureClient here.
+    // The ref count could be 1 and RecycleCallback will be called if we clear
+    // the ref count here. That breaks the whole mechanism. (RecycleCallback
+    // should be called from layers)
+    mGraphBuffer = nullptr;
+  }
+
+private:
+  // Because TextureClient calls RecycleCallbackl when ref count is 1, so we
+  // should hold only one reference here and use raw pointer when out of this
+  // class.
+  RefPtr<layers::TextureClient> mTextureClient;
+
+  // It is protected by mMonitor.
+  sp<android::GraphicBuffer> mGraphBuffer;
+
+  // It is protected by mMonitor.
+  MozPromiseHolder<TextureClientRecyclePromise> mPromise;
+
+  Monitor mMonitor;
+};
+
+GonkBufferData::GonkBufferData(bool aLiveInLocal,
+                               GonkOmxPlatformLayer* aGonkPlatformLayer)
+  : BufferData(nullptr)
+  , mId(0)
+  , mGonkPlatformLayer(aGonkPlatformLayer)
 {
   if (!aLiveInLocal) {
-    mLocalBuffer = new OMX_BUFFERHEADERTYPE;
-    PodZero(mLocalBuffer.get());
-    // aMemory is a IPC memory, it is safe to use it here.
-    mLocalBuffer->pBuffer = (OMX_U8*)aMemory->pointer();
-    mBuffer = mLocalBuffer.get();
+    mMirrorBuffer = new OMX_BUFFERHEADERTYPE;
+    PodZero(mMirrorBuffer.get());
+    mBuffer = mMirrorBuffer.get();
+  }
+}
+
+void
+GonkBufferData::ReleaseBuffer()
+{
+  if (mTextureClientRecycleHandler) {
+    mTextureClientRecycleHandler->Shutdown();
+    mTextureClientRecycleHandler = nullptr;
   }
 }
 
+nsresult
+GonkBufferData::InitSharedMemory(android::IMemory* aMemory)
+{
+  MOZ_RELEASE_ASSERT(mMirrorBuffer.get());
+
+  // aMemory is a IPC memory, it is safe to use it here.
+  mBuffer->pBuffer = (OMX_U8*)aMemory->pointer();
+  mBuffer->nAllocLen = aMemory->size();
+  return NS_OK;
+}
+
+nsresult
+GonkBufferData::InitLocalBuffer(IOMX::buffer_id aId)
+{
+  MOZ_RELEASE_ASSERT(!mMirrorBuffer.get());
+
+  mBuffer = (OMX_BUFFERHEADERTYPE*)aId;
+  return NS_OK;
+}
+
+nsresult
+GonkBufferData::InitGraphicBuffer(OMX_VIDEO_PORTDEFINITIONTYPE& aDef)
+{
+  mTextureClientRecycleHandler = new GonkTextureClientRecycleHandler(aDef);
+
+  if (!mTextureClientRecycleHandler->GetGraphicBuffer()) {
+    return NS_ERROR_FAILURE;
+  }
+
+  return NS_OK;
+}
+
+already_AddRefed<MediaData>
+GonkBufferData::GetPlatformMediaData()
+{
+  if (mGonkPlatformLayer->GetTrackInfo()->GetAsAudioInfo()) {
+    // This is audio decoding.
+    return nullptr;
+  }
+
+  if (!mTextureClientRecycleHandler) {
+    // There is no GraphicBuffer, it should fallback to normal YUV420 VideoData.
+    return nullptr;
+  }
+
+  VideoInfo info(*mGonkPlatformLayer->GetTrackInfo()->GetAsVideoInfo());
+  RefPtr<VideoData> data =
+    VideoData::CreateAndCopyIntoTextureClient(info,
+                                              0,
+                                              mBuffer->nTimeStamp,
+                                              1,
+                                              mTextureClientRecycleHandler->GetTextureClient(),
+                                              false,
+                                              0,
+                                              info.ImageRect());
+  LOG("%p, disp width %d, height %d, pic width %d, height %d, time %ld",
+      this, info.mDisplay.width, info.mDisplay.height,
+      info.mImage.width, info.mImage.height, mBuffer->nTimeStamp);
+
+  // Get TextureClient Promise here to wait for resolved.
+  RefPtr<GonkBufferData> self(this);
+  mTextureClientRecycleHandler->WaitforRecycle()
+    ->Then(mGonkPlatformLayer->GetTaskQueue(), __func__,
+           [self] () {
+             // Waiting for texture to be freed.
+             if (self->mTextureClientRecycleHandler) {
+               self->mTextureClientRecycleHandler->GetTextureClient()->WaitForBufferOwnership();
+             }
+             self->mPromise.ResolveIfExists(self, __func__);
+           },
+           [self] () {
+             OmxBufferFailureHolder failure(OMX_ErrorUndefined, self);
+             self->mPromise.RejectIfExists(failure, __func__);
+           });
+
+  return data.forget();
+}
+
 GonkOmxPlatformLayer::GonkOmxPlatformLayer(OmxDataDecoder* aDataDecoder,
                                            OmxPromiseLayer* aPromiseLayer,
-                                           TaskQueue* aTaskQueue)
+                                           TaskQueue* aTaskQueue,
+                                           layers::ImageContainer* aImageContainer)
   : mTaskQueue(aTaskQueue)
+  , mImageContainer(aImageContainer)
   , mNode(0)
-  , mQuirks(0)
-  , mUsingHardwareCodec(false)
 {
   mOmxObserver = new GonkOmxObserver(mTaskQueue, aPromiseLayer, aDataDecoder);
 }
@@ -153,7 +363,7 @@ GonkOmxPlatformLayer::AllocateOmxBuffer(OMX_DIRTYPE aType,
   // Get port definition.
   OMX_PARAM_PORTDEFINITIONTYPE def;
   nsTArray<uint32_t> portindex;
-  GetPortIndex(portindex);
+  GetPortIndices(portindex);
   for (auto idx : portindex) {
     InitOmxParameter(&def);
     def.nPortIndex = idx;
@@ -169,8 +379,26 @@ GonkOmxPlatformLayer::AllocateOmxBuffer(OMX_DIRTYPE aType,
     }
   }
 
-  size_t t = def.nBufferCountActual * def.nBufferSize;
-  LOG("Buffer count %d, buffer size %d", def.nBufferCountActual, def.nBufferSize);
+  size_t t = 0;
+
+  // Configure video output GraphicBuffer for video decoding acceleration.
+  bool useGralloc = false;
+  if (aType == OMX_DirOutput && mQuirks.test(kRequiresAllocateBufferOnOutputPorts) &&
+      (def.eDomain == OMX_PortDomainVideo)) {
+    if (NS_FAILED(EnableOmxGraphicBufferPort(def))) {
+      return NS_ERROR_FAILURE;
+    }
+
+    LOG("Enable OMX GraphicBuffer port, number %d, width %d, height %d", def.nBufferCountActual,
+        def.format.video.nFrameWidth, def.format.video.nFrameHeight);
+
+    useGralloc = true;
+
+    t = 1024; // MemoryDealer doesn't like 0, it's just for MemoryDealer happy.
+  } else {
+    t = def.nBufferCountActual * def.nBufferSize;
+    LOG("Buffer count %d, buffer size %d", def.nBufferCountActual, def.nBufferSize);
+  }
 
   bool liveinlocal = mOmx->livesLocally(mNode, getpid());
 
@@ -178,24 +406,47 @@ GonkOmxPlatformLayer::AllocateOmxBuffer(OMX_DIRTYPE aType,
   // lives in mediaserver.
   mMemoryDealer[aType] = new MemoryDealer(t, "Gecko-OMX");
   for (OMX_U32 i = 0; i < def.nBufferCountActual; ++i) {
-    sp<IMemory> mem = mMemoryDealer[aType]->allocate(def.nBufferSize);
-    MOZ_ASSERT(mem.get());
-
+    RefPtr<GonkBufferData> buffer;
     IOMX::buffer_id bufferID;
     status_t st;
-
-    if ((mQuirks & OMXCodec::kRequiresAllocateBufferOnInputPorts && aType == OMX_DirInput) ||
-        (mQuirks & OMXCodec::kRequiresAllocateBufferOnOutputPorts && aType == OMX_DirOutput)) {
-      st = mOmx->allocateBufferWithBackup(mNode, aType, mem, &bufferID);
+    nsresult rv;
+
+    buffer = new GonkBufferData(liveinlocal, this);
+    if (useGralloc) {
+      // Buffer is lived remotely. Use GraphicBuffer for decoded video frame display.
+      rv = buffer->InitGraphicBuffer(def.format.video);
+      NS_ENSURE_SUCCESS(rv, rv);
+      st = mOmx->useGraphicBuffer(mNode,
+                                  def.nPortIndex,
+                                  buffer->mTextureClientRecycleHandler->GetGraphicBuffer(),
+                                  &bufferID);
+      CHECK_ERR(st);
     } else {
-      st = mOmx->useBuffer(mNode, aType, mem, &bufferID);
+      sp<IMemory> mem = mMemoryDealer[aType]->allocate(def.nBufferSize);
+      MOZ_ASSERT(mem.get());
+
+      if ((mQuirks.test(kRequiresAllocateBufferOnInputPorts) && aType == OMX_DirInput) ||
+          (mQuirks.test(kRequiresAllocateBufferOnOutputPorts) && aType == OMX_DirOutput)) {
+        // Buffer is lived remotely. We allocate a local OMX_BUFFERHEADERTYPE
+        // as the mirror of the remote OMX_BUFFERHEADERTYPE.
+        st = mOmx->allocateBufferWithBackup(mNode, aType, mem, &bufferID);
+        CHECK_ERR(st);
+        rv = buffer->InitSharedMemory(mem.get());
+        NS_ENSURE_SUCCESS(rv, rv);
+      } else {
+        // Buffer is lived locally, bufferID is the actually OMX_BUFFERHEADERTYPE
+        // pointer.
+        st = mOmx->useBuffer(mNode, aType, mem, &bufferID);
+        CHECK_ERR(st);
+        rv = buffer->InitLocalBuffer(bufferID);
+        NS_ENSURE_SUCCESS(rv, rv);
+      }
     }
 
-    if (st != OK) {
-      return NS_ERROR_FAILURE;
-    }
+    rv = buffer->SetBufferId(bufferID);
+    NS_ENSURE_SUCCESS(rv, rv);
 
-    aBufferList->AppendElement(new GonkBufferData(bufferID, liveinlocal, mem.get()));
+    aBufferList->AppendElement(buffer);
   }
 
   return NS_OK;
@@ -206,12 +457,15 @@ GonkOmxPlatformLayer::ReleaseOmxBuffer(OMX_DIRTYPE aType,
                                        BUFFERLIST* aBufferList)
 {
   status_t st;
-  for (uint32_t i = 0; i < aBufferList->Length(); i++) {
-    IOMX::buffer_id id = (OMX_BUFFERHEADERTYPE*) aBufferList->ElementAt(i)->ID();
+  uint32_t len = aBufferList->Length();
+  for (uint32_t i = 0; i < len; i++) {
+    GonkBufferData* buffer = static_cast<GonkBufferData*>(aBufferList->ElementAt(i).get());
+    IOMX::buffer_id id = (OMX_BUFFERHEADERTYPE*) buffer->ID();
     st = mOmx->freeBuffer(mNode, aType, id);
     if (st != OK) {
       return NS_ERROR_FAILURE;
     }
+    buffer->ReleaseBuffer();
   }
   aBufferList->Clear();
   mMemoryDealer[aType].clear();
@@ -219,6 +473,17 @@ GonkOmxPlatformLayer::ReleaseOmxBuffer(OMX_DIRTYPE aType,
   return NS_OK;
 }
 
+nsresult
+GonkOmxPlatformLayer::EnableOmxGraphicBufferPort(OMX_PARAM_PORTDEFINITIONTYPE& aDef)
+{
+  status_t st;
+
+  st = mOmx->enableGraphicBuffers(mNode, aDef.nPortIndex, OMX_TRUE);
+  CHECK_ERR(st);
+
+  return NS_OK;
+}
+
 OMX_ERRORTYPE
 GonkOmxPlatformLayer::GetState(OMX_STATETYPE* aType)
 {
@@ -261,6 +526,7 @@ GonkOmxPlatformLayer::Shutdown()
 OMX_ERRORTYPE
 GonkOmxPlatformLayer::InitOmxToStateLoaded(const TrackInfo* aInfo)
 {
+  mInfo = aInfo;
   status_t err = mOmxClient.connect();
   if (err != OK) {
       return OMX_ErrorUndefined;
@@ -270,36 +536,17 @@ GonkOmxPlatformLayer::InitOmxToStateLoaded(const TrackInfo* aInfo)
     return OMX_ErrorUndefined;
   }
 
-  // In Gonk, the software compoment name has prefix "OMX.google". It needs to
-  // have a way to use hardware codec first.
-  android::Vector<OMXCodec::CodecNameAndQuirks> matchingCodecs;
-  const char* swcomponent = nullptr;
-  OMXCodec::findMatchingCodecs(aInfo->mMimeType.Data(),
-                               0,
-                               nullptr,
-                               0,
-                               &matchingCodecs);
-  for (uint32_t i = 0; i < matchingCodecs.size(); i++) {
-    const char* componentName = matchingCodecs.itemAt(i).mName.string();
-    if (IsSoftwareCodec(componentName)) {
-      swcomponent = componentName;
-    } else {
-      // Try to use hardware codec first.
-      if (LoadComponent(componentName)) {
-        mUsingHardwareCodec = true;
+  LOG("find componenet for mime type %s", mInfo->mMimeType.Data());
+
+  nsTArray<ComponentInfo> components;
+  if (FindComponents(mInfo->mMimeType, &components)) {
+    for (auto comp : components) {
+      if (LoadComponent(comp)) {
         return OMX_ErrorNone;
       }
     }
   }
 
-  // TODO: in android ICS, the software codec is allocated in mediaserver by
-  //       default, it may be necessay to allocate it in local process.
-  //
-  // fallback to sw codec
-  if (LoadComponent(swcomponent)) {
-    return OMX_ErrorNone;
-  }
-
   LOG("no component is loaded");
   return OMX_ErrorUndefined;
 }
@@ -318,7 +565,7 @@ GonkOmxPlatformLayer::EmptyThisBuffer(BufferData* aData)
 OMX_ERRORTYPE
 GonkOmxPlatformLayer::FillThisBuffer(BufferData* aData)
 {
-  return (OMX_ERRORTYPE)mOmx->fillBuffer(mNode, (IOMX::buffer_id)aData->mBuffer);
+  return (OMX_ERRORTYPE)mOmx->fillBuffer(mNode, (IOMX::buffer_id)aData->ID());
 }
 
 OMX_ERRORTYPE
@@ -330,24 +577,95 @@ GonkOmxPlatformLayer::SendCommand(OMX_COMMANDTYPE aCmd,
 }
 
 bool
-GonkOmxPlatformLayer::LoadComponent(const char* aName)
+GonkOmxPlatformLayer::LoadComponent(const ComponentInfo& aComponent)
 {
-  status_t err = mOmx->allocateNode(aName, mOmxObserver, &mNode);
+  status_t err = mOmx->allocateNode(aComponent.mName, mOmxObserver, &mNode);
   if (err == OK) {
-    OMXCodec::findCodecQuirks(aName, &mQuirks);
-    LOG("Load OpenMax component %s, quirks %x, live locally %d",
-        aName, mQuirks, mOmx->livesLocally(mNode, getpid()));
+    mQuirks = aComponent.mQuirks;
+    LOG("Load OpenMax component %s, alloc input %d, alloc output %d, live locally %d",
+        aComponent.mName, mQuirks.test(kRequiresAllocateBufferOnInputPorts),
+        mQuirks.test(kRequiresAllocateBufferOnOutputPorts),
+        mOmx->livesLocally(mNode, getpid()));
     return true;
   }
   return false;
 }
 
-template<class T> void
-GonkOmxPlatformLayer::InitOmxParameter(T* aParam)
+layers::ImageContainer*
+GonkOmxPlatformLayer::GetImageContainer()
+{
+  return mImageContainer;
+}
+
+const TrackInfo*
+GonkOmxPlatformLayer::GetTrackInfo()
+{
+  return mInfo;
+}
+
+bool
+GonkOmxPlatformLayer::FindComponents(const nsACString& aMimeType,
+                                     nsTArray<ComponentInfo>* aComponents)
+{
+  static const MediaCodecList* codecs = MediaCodecList::getInstance();
+
+  bool useHardwareCodecOnly = false;
+
+  // H264 and H263 has different profiles, software codec doesn't support high profile.
+  // So we use hardware codec only.
+  if (!IsInEmulator() &&
+      (aMimeType.EqualsLiteral("video/avc") ||
+       aMimeType.EqualsLiteral("video/mp4") ||
+       aMimeType.EqualsLiteral("video/mp4v-es") ||
+       aMimeType.EqualsLiteral("video/3gp"))) {
+    useHardwareCodecOnly = true;
+  }
+
+  const char* mime = aMimeType.Data();
+  // Translate VP8 MIME type to Android format.
+  if (aMimeType.EqualsLiteral("video/webm; codecs=vp8")) {
+    mime = "video/x-vnd.on2.vp8";
+  }
+
+  size_t start = 0;
+  bool found = false;
+  while (true) {
+    ssize_t index = codecs->findCodecByType(mime, false /* encoder */, start);
+    if (index < 0) {
+      break;
+    }
+    start = index + 1;
+
+    const char* name = codecs->getCodecName(index);
+    if (IsSoftwareCodec(name) && useHardwareCodecOnly) {
+      continue;
+    }
+
+    found = true;
+
+    if (!aComponents) {
+      continue;
+    }
+    ComponentInfo* comp = aComponents->AppendElement();
+    comp->mName = name;
+    if (codecs->codecHasQuirk(index, "requires-allocate-on-input-ports")) {
+      comp->mQuirks.set(kRequiresAllocateBufferOnInputPorts);
+    }
+    if (codecs->codecHasQuirk(index, "requires-allocate-on-output-ports")) {
+      comp->mQuirks.set(kRequiresAllocateBufferOnOutputPorts);
+    }
+  }
+
+  return found;
+}
+
+OMX_VIDEO_CODINGTYPE
+GonkOmxPlatformLayer::CompressionFormat()
 {
-  PodZero(aParam);
-  aParam->nSize = sizeof(T);
-  aParam->nVersion.s.nVersionMajor = 1;
+  MOZ_ASSERT(mInfo);
+
+  return mInfo->mMimeType.EqualsLiteral("video/webm; codecs=vp8") ?
+    ANDROID_OMX_VIDEO_CodingVP8 : OmxPlatformLayer::CompressionFormat();
 }
 
 } // mozilla
diff --git a/dom/media/platforms/omx/GonkOmxPlatformLayer.h b/dom/media/platforms/omx/GonkOmxPlatformLayer.h
index c13a5c6..aaa8c654 100644
--- a/dom/media/platforms/omx/GonkOmxPlatformLayer.h
+++ b/dom/media/platforms/omx/GonkOmxPlatformLayer.h
@@ -9,66 +9,124 @@
 
 #pragma GCC visibility push(default)
 
-#include "OmxPlatformLayer.h"
-#include "OMX_Component.h"
+#include <bitset>
+
 #include <utils/RefBase.h>
 #include <media/stagefright/OMXClient.h>
+#include "nsAutoPtr.h"
+
+#include "OMX_Component.h"
+
+#include "OmxPlatformLayer.h"
+
+class nsACString;
 
 namespace android {
-class MemoryDealer;
 class IMemory;
+class MemoryDealer;
 }
 
 namespace mozilla {
 
 class GonkOmxObserver;
+class GonkOmxPlatformLayer;
+class GonkTextureClientRecycleHandler;
 
 /*
  * Due to Android's omx node could live in local process (client) or remote
- * process (mediaserver).
+ * process (mediaserver). And there are 3 kinds of buffer in Android OMX.
  *
- * When it is in local process, the IOMX::buffer_id is OMX_BUFFERHEADERTYPE
+ * 1.
+ * When buffer is in local process, the IOMX::buffer_id is OMX_BUFFERHEADERTYPE
  * pointer actually, it is safe to use it directly.
  *
- * When it is in remote process, the OMX_BUFFERHEADERTYPE pointer is 'IN' the
+ * 2.
+ * When buffer is in remote process, the OMX_BUFFERHEADERTYPE pointer is 'IN' the
  * remote process. It can't be used in local process, so here it allocates a
- * local OMX_BUFFERHEADERTYPE.
+ * local OMX_BUFFERHEADERTYPE. The raw/decoded data is in the android shared
+ * memory, IMemory.
+ *
+ * 3.
+ * When buffer is in remote process for the display output port. It uses
+ * GraphicBuffer to accelerate the decoding and display.
+ *
  */
 class GonkBufferData : public OmxPromiseLayer::BufferData {
 protected:
   virtual ~GonkBufferData() {}
 
 public:
-  // aMemory is an IPC based memory which will be used as the pBuffer in
-  // mLocalBuffer.
-  GonkBufferData(android::IOMX::buffer_id aId, bool aLiveInLocal, android::IMemory* aMemory);
+  GonkBufferData(bool aLiveInLocal,
+                 GonkOmxPlatformLayer* aLayer);
 
   BufferID ID() override
   {
     return mId;
   }
 
+  already_AddRefed<MediaData> GetPlatformMediaData() override;
+
   bool IsLocalBuffer()
   {
-    return !!mLocalBuffer.get();
+    return !!mMirrorBuffer.get();
+  }
+
+  void ReleaseBuffer();
+
+  nsresult SetBufferId(android::IOMX::buffer_id aId)
+  {
+    mId = aId;
+    return NS_OK;
   }
 
+  // The mBuffer is in local process. And aId is actually the OMX_BUFFERHEADERTYPE
+  // pointer. It doesn't need a mirror buffer.
+  nsresult InitLocalBuffer(android::IOMX::buffer_id aId);
+
+  // aMemory is an IPC based memory which will be used as the pBuffer in
+  // mBuffer. And the mBuffer will be the mirror OMX_BUFFERHEADERTYPE
+  // of the one in the remote process.
+  nsresult InitSharedMemory(android::IMemory* aMemory);
+
+  // GraphicBuffer is for video decoding acceleration on output port.
+  // Then mBuffer is the mirror OMX_BUFFERHEADERTYPE of the one in the remote
+  // process.
+  nsresult InitGraphicBuffer(OMX_VIDEO_PORTDEFINITIONTYPE& aDef);
+
   // Android OMX uses this id to pass the buffer between OMX component and
   // client.
   android::IOMX::buffer_id mId;
 
-  // mLocalBuffer are used only when the omx node is in mediaserver.
+  // mMirrorBuffer are used only when the omx node is in mediaserver.
   // Due to IPC problem, the mId is the OMX_BUFFERHEADERTYPE address in mediaserver.
   // It can't mapping to client process, so we need a local OMX_BUFFERHEADERTYPE
-  // here.
-  nsAutoPtr<OMX_BUFFERHEADERTYPE> mLocalBuffer;
+  // here to mirror the remote OMX_BUFFERHEADERTYPE in mediaserver.
+  nsAutoPtr<OMX_BUFFERHEADERTYPE> mMirrorBuffer;
+
+  // It creates GraphicBuffer and manages TextureClient.
+  RefPtr<GonkTextureClientRecycleHandler> mTextureClientRecycleHandler;
+
+  GonkOmxPlatformLayer* mGonkPlatformLayer;
 };
 
 class GonkOmxPlatformLayer : public OmxPlatformLayer {
 public:
+  enum {
+    kRequiresAllocateBufferOnInputPorts = 0,
+    kRequiresAllocateBufferOnOutputPorts,
+    QUIRKS,
+  };
+  typedef std::bitset<QUIRKS> Quirks;
+
+  struct ComponentInfo {
+    const char* mName;
+    Quirks mQuirks;
+  };
+
   GonkOmxPlatformLayer(OmxDataDecoder* aDataDecoder,
                        OmxPromiseLayer* aPromiseLayer,
-                       TaskQueue* aTaskQueue);
+                       TaskQueue* aTaskQueue,
+                       layers::ImageContainer* aImageContainer);
 
   nsresult AllocateOmxBuffer(OMX_DIRTYPE aType, BUFFERLIST* aBufferList) override;
 
@@ -96,18 +154,36 @@ public:
 
   nsresult Shutdown() override;
 
-  // TODO:
-  // There is another InitOmxParameter in OmxDataDecoder. They need to combinate
-  // to one function.
-  template<class T> void InitOmxParameter(T* aParam);
+  static bool FindComponents(const nsACString& aMimeType,
+                             nsTArray<ComponentInfo>* aComponents = nullptr);
+
+  // Android/QCOM decoder uses its own OMX_VIDEO_CodingVP8 definition in
+  // frameworks/native/media/include/openmax/OMX_Video.h, not the one defined
+  // in OpenMAX v1.1.2 OMX_VideoExt.h
+  OMX_VIDEO_CODINGTYPE CompressionFormat() override;
 
 protected:
-  bool LoadComponent(const char* aName);
+  friend GonkBufferData;
+
+  layers::ImageContainer* GetImageContainer();
+
+  const TrackInfo* GetTrackInfo();
+
+  TaskQueue* GetTaskQueue()
+  {
+    return mTaskQueue;
+  }
+
+  nsresult EnableOmxGraphicBufferPort(OMX_PARAM_PORTDEFINITIONTYPE& aDef);
+
+  bool LoadComponent(const ComponentInfo& aComponent);
 
   friend class GonkOmxObserver;
 
   RefPtr<TaskQueue> mTaskQueue;
 
+  RefPtr<layers::ImageContainer> mImageContainer;
+
   // OMX_DirInput is 0, OMX_DirOutput is 1.
   android::sp<android::MemoryDealer> mMemoryDealer[2];
 
@@ -119,9 +195,7 @@ protected:
 
   android::OMXClient mOmxClient;
 
-  uint32_t mQuirks;
-
-  bool mUsingHardwareCodec;
+  Quirks mQuirks;
 };
 
 }
diff --git a/dom/media/platforms/omx/OmxDataDecoder.cpp b/dom/media/platforms/omx/OmxDataDecoder.cpp
index 2a9bee7..0dbe1be 100644
--- a/dom/media/platforms/omx/OmxDataDecoder.cpp
+++ b/dom/media/platforms/omx/OmxDataDecoder.cpp
@@ -5,17 +5,29 @@
  * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
 
 #include "OmxDataDecoder.h"
-#include "OMX_Types.h"
-#include "OMX_Component.h"
+
 #include "OMX_Audio.h"
+#include "OMX_Component.h"
+#include "OMX_Types.h"
+
+#include "OmxPlatformLayer.h"
 
-extern mozilla::LogModule* GetPDMLog();
 
 #ifdef LOG
 #undef LOG
+#undef LOGL
 #endif
 
-#define LOG(arg, ...) MOZ_LOG(GetPDMLog(), mozilla::LogLevel::Debug, ("OmxDataDecoder::%s: " arg, __func__, ##__VA_ARGS__))
+extern mozilla::LogModule* GetPDMLog();
+
+#define LOG(arg, ...) MOZ_LOG(GetPDMLog(), mozilla::LogLevel::Debug, ("OmxDataDecoder(%p)::%s: " arg, this, __func__, ##__VA_ARGS__))
+
+#define LOGL(arg, ...)                                                     \
+  {                                                                        \
+    void* p = self;                                              \
+    MOZ_LOG(GetPDMLog(), mozilla::LogLevel::Debug,                      \
+            ("OmxDataDecoder(%p)::%s: " arg, p, __func__, ##__VA_ARGS__)); \
+  }
 
 #define CHECK_OMX_ERR(err)     \
   if (err != OMX_ErrorNone) {  \
@@ -23,7 +35,6 @@ extern mozilla::LogModule* GetPDMLog();
     return;                    \
   }                            \
 
-
 namespace mozilla {
 
 static const char*
@@ -54,28 +65,55 @@ StateTypeToStr(OMX_STATETYPE aType)
   }
 }
 
-// There should be 2 ports and port number start from 0.
-void GetPortIndex(nsTArray<uint32_t>& aPortIndex) {
-  aPortIndex.AppendElement(0);
-  aPortIndex.AppendElement(1);
-}
+// A helper class to retrieve AudioData or VideoData.
+class MediaDataHelper {
+protected:
+  virtual ~MediaDataHelper() {}
+
+public:
+  NS_INLINE_DECL_THREADSAFE_REFCOUNTING(MediaDataHelper)
+
+  MediaDataHelper(const TrackInfo* aTrackInfo,
+                  layers::ImageContainer* aImageContainer,
+                  OmxPromiseLayer* aOmxLayer);
+
+  already_AddRefed<MediaData> GetMediaData(BufferData* aBufferData, bool& aPlatformDepenentData);
+
+protected:
+  already_AddRefed<AudioData> CreateAudioData(BufferData* aBufferData);
+
+  already_AddRefed<VideoData> CreateYUV420VideoData(BufferData* aBufferData);
+
+  const TrackInfo* mTrackInfo;
+
+  OMX_PARAM_PORTDEFINITIONTYPE mOutputPortDef;
+
+  // audio output
+  MediaQueue<AudioData> mAudioQueue;
+
+  AudioCompactor mAudioCompactor;
+
+  // video output
+  RefPtr<layers::ImageContainer> mImageContainer;
+};
 
 OmxDataDecoder::OmxDataDecoder(const TrackInfo& aTrackInfo,
-                               MediaDataDecoderCallback* aCallback)
+                               MediaDataDecoderCallback* aCallback,
+                               layers::ImageContainer* aImageContainer)
   : mMonitor("OmxDataDecoder")
   , mOmxTaskQueue(CreateMediaDecodeTaskQueue())
+  , mImageContainer(aImageContainer)
   , mWatchManager(this, mOmxTaskQueue)
   , mOmxState(OMX_STATETYPE::OMX_StateInvalid, "OmxDataDecoder::mOmxState")
   , mTrackInfo(aTrackInfo.Clone())
   , mFlushing(false)
-  , mShutdown(false)
+  , mShuttingDown(false)
   , mCheckingInputExhausted(false)
   , mPortSettingsChanged(-1, "OmxDataDecoder::mPortSettingsChanged")
-  , mAudioCompactor(mAudioQueue)
   , mCallback(aCallback)
 {
-  LOG("(%p)", this);
-  mOmxLayer = new OmxPromiseLayer(mOmxTaskQueue, this);
+  LOG("");
+  mOmxLayer = new OmxPromiseLayer(mOmxTaskQueue, this, aImageContainer);
 
   nsCOMPtr<nsIRunnable> r =
     NS_NewRunnableMethod(this, &OmxDataDecoder::InitializationTask);
@@ -84,9 +122,7 @@ OmxDataDecoder::OmxDataDecoder(const TrackInfo& aTrackInfo,
 
 OmxDataDecoder::~OmxDataDecoder()
 {
-  LOG("(%p)", this);
-  mWatchManager.Shutdown();
-  mOmxTaskQueue->AwaitShutdownAndIdle();
+  LOG("");
 }
 
 void
@@ -99,21 +135,27 @@ OmxDataDecoder::InitializationTask()
 void
 OmxDataDecoder::EndOfStream()
 {
-  LOG("(%p)", this);
+  LOG("");
   MOZ_ASSERT(mOmxTaskQueue->IsCurrentThreadIn());
 
+  mFlushing = true;
   RefPtr<OmxDataDecoder> self = this;
-  nsCOMPtr<nsIRunnable> r =
-    NS_NewRunnableFunction([self] () {
-      self->mCallback->DrainComplete();
-    });
-  mReaderTaskQueue->Dispatch(r.forget());
+  mOmxLayer->SendCommand(OMX_CommandFlush, OMX_ALL, nullptr)
+    ->Then(mReaderTaskQueue, __func__,
+        [self] () {
+          self->mFlushing = false;
+          self->mCallback->DrainComplete();
+        },
+        [self] () {
+          self->mFlushing = false;
+          self->mCallback->DrainComplete();
+        });
 }
 
 RefPtr<MediaDataDecoder::InitPromise>
 OmxDataDecoder::Init()
 {
-  LOG("(%p)", this);
+  LOG("");
   mReaderTaskQueue = AbstractThread::GetCurrent()->AsTaskQueue();
   MOZ_ASSERT(mReaderTaskQueue);
 
@@ -123,16 +165,12 @@ OmxDataDecoder::Init()
   // TODO: it needs to get permission from resource manager before allocating
   //       Omx component.
   InvokeAsync(mOmxTaskQueue, mOmxLayer.get(), __func__, &OmxPromiseLayer::Init,
-              mOmxTaskQueue, mTrackInfo.get())
-    ->Then(mReaderTaskQueue, __func__,
+              mTrackInfo.get())
+    ->Then(mOmxTaskQueue, __func__,
       [self] () {
         // Omx state should be OMX_StateIdle.
-        nsCOMPtr<nsIRunnable> r =
-          NS_NewRunnableFunction([self] () {
-            self->mOmxState = self->mOmxLayer->GetState();
-            MOZ_ASSERT(self->mOmxState != OMX_StateIdle);
-          });
-        self->mOmxTaskQueue->Dispatch(r.forget());
+        self->mOmxState = self->mOmxLayer->GetState();
+        MOZ_ASSERT(self->mOmxState != OMX_StateIdle);
       },
       [self] () {
         self->RejectInitPromise(DecoderFailureReason::INIT_ERROR, __func__);
@@ -144,7 +182,7 @@ OmxDataDecoder::Init()
 nsresult
 OmxDataDecoder::Input(MediaRawData* aSample)
 {
-  LOG("(%p) sample %p", this, aSample);
+  LOG("sample %p", aSample);
   MOZ_ASSERT(mInitPromise.IsEmpty());
 
   RefPtr<OmxDataDecoder> self = this;
@@ -168,7 +206,7 @@ OmxDataDecoder::Input(MediaRawData* aSample)
 nsresult
 OmxDataDecoder::Flush()
 {
-  LOG("(%p)", this);
+  LOG("");
 
   mFlushing = true;
 
@@ -190,11 +228,8 @@ OmxDataDecoder::Flush()
 nsresult
 OmxDataDecoder::Drain()
 {
-  LOG("(%p)", this);
+  LOG("");
 
-  // TODO: For video decoding, it needs to copy the latest video frame to yuv
-  //       and output to layer again, because all video buffers will be released
-  //       later.
   nsCOMPtr<nsIRunnable> r =
     NS_NewRunnableMethod(this, &OmxDataDecoder::SendEosBuffer);
   mOmxTaskQueue->Dispatch(r.forget());
@@ -205,44 +240,46 @@ OmxDataDecoder::Drain()
 nsresult
 OmxDataDecoder::Shutdown()
 {
-  LOG("(%p)", this);
+  LOG("");
 
-  mShutdown = true;
+  mShuttingDown = true;
 
   nsCOMPtr<nsIRunnable> r =
     NS_NewRunnableMethod(this, &OmxDataDecoder::DoAsyncShutdown);
   mOmxTaskQueue->Dispatch(r.forget());
 
+  {
+    // DoAsyncShutdown() will be running for a while, it could be still running
+    // when reader releasing the decoder and then it causes problem. To avoid it,
+    // Shutdown() must block until DoAsyncShutdown() is completed.
+    MonitorAutoLock lock(mMonitor);
+    while (mShuttingDown) {
+      lock.Wait();
+    }
+  }
+
+  mOmxTaskQueue->BeginShutdown();
+  mOmxTaskQueue->AwaitShutdownAndIdle();
+
   return NS_OK;
 }
 
 void
 OmxDataDecoder::DoAsyncShutdown()
 {
-  LOG("(%p)", this);
+  LOG("");
   MOZ_ASSERT(mOmxTaskQueue->IsCurrentThreadIn());
-  MOZ_ASSERT(mFlushing);
+  MOZ_ASSERT(!mFlushing);
 
   mWatchManager.Unwatch(mOmxState, &OmxDataDecoder::OmxStateRunner);
   mWatchManager.Unwatch(mPortSettingsChanged, &OmxDataDecoder::PortSettingsChanged);
 
-  // Do flush so all port can be returned to client.
+  // Flush to all ports, so all buffers can be returned from component.
   RefPtr<OmxDataDecoder> self = this;
   mOmxLayer->SendCommand(OMX_CommandFlush, OMX_ALL, nullptr)
     ->Then(mOmxTaskQueue, __func__,
            [self] () -> RefPtr<OmxCommandPromise> {
-             LOG("DoAsyncShutdown: flush complete, collecting buffers...");
-             self->CollectBufferPromises(OMX_DirMax)
-               ->Then(self->mOmxTaskQueue, __func__,
-                   [self] () {
-                     LOG("DoAsyncShutdown: releasing all buffers.");
-                     self->ReleaseBuffers(OMX_DirInput);
-                     self->ReleaseBuffers(OMX_DirOutput);
-                   },
-                   [self] () {
-                     self->mOmxLayer->Shutdown();
-                   });
-
+             LOGL("DoAsyncShutdown: flush complete");
              return self->mOmxLayer->SendCommand(OMX_CommandStateSet, OMX_StateIdle, nullptr);
            },
            [self] () {
@@ -251,8 +288,22 @@ OmxDataDecoder::DoAsyncShutdown()
     ->CompletionPromise()
     ->Then(mOmxTaskQueue, __func__,
            [self] () -> RefPtr<OmxCommandPromise> {
-             LOG("DoAsyncShutdown: OMX_StateIdle");
-             return self->mOmxLayer->SendCommand(OMX_CommandStateSet, OMX_StateLoaded, nullptr);
+             RefPtr<OmxCommandPromise> p =
+               self->mOmxLayer->SendCommand(OMX_CommandStateSet, OMX_StateLoaded, nullptr);
+
+             // According to spec 3.1.1.2.2.1:
+             // OMX_StateLoaded needs to be sent before releasing buffers.
+             // And state transition from OMX_StateIdle to OMX_StateLoaded
+             // is completed when all of the buffers have been removed
+             // from the component.
+             // Here the buffer promises are not resolved due to displaying
+             // in layer, it needs to wait before the layer returns the
+             // buffers.
+             LOGL("DoAsyncShutdown: releasing buffers...");
+             self->ReleaseBuffers(OMX_DirInput);
+             self->ReleaseBuffers(OMX_DirOutput);
+
+             return p;
            },
            [self] () {
              self->mOmxLayer->Shutdown();
@@ -260,98 +311,94 @@ OmxDataDecoder::DoAsyncShutdown()
     ->CompletionPromise()
     ->Then(mOmxTaskQueue, __func__,
            [self] () {
-             LOG("DoAsyncShutdown: OMX_StateLoaded, it is safe to shutdown omx");
+             LOGL("DoAsyncShutdown: OMX_StateLoaded, it is safe to shutdown omx");
              self->mOmxLayer->Shutdown();
+             self->mWatchManager.Shutdown();
+             self->mOmxLayer = nullptr;
+             self->mMediaDataHelper = nullptr;
+
+             MonitorAutoLock lock(self->mMonitor);
+             self->mShuttingDown = false;
+             self->mMonitor.Notify();
            },
            [self] () {
              self->mOmxLayer->Shutdown();
+             self->mWatchManager.Shutdown();
+             self->mOmxLayer = nullptr;
+             self->mMediaDataHelper = nullptr;
+
+             MonitorAutoLock lock(self->mMonitor);
+             self->mShuttingDown = false;
+             self->mMonitor.Notify();
            });
 }
 
 void
-OmxDataDecoder::CheckIfInputExhausted()
+OmxDataDecoder::FillBufferDone(BufferData* aData)
 {
-  MOZ_ASSERT(mOmxTaskQueue->IsCurrentThreadIn());
-  MOZ_ASSERT(!mCheckingInputExhausted);
-
-  mCheckingInputExhausted = false;
+  MOZ_ASSERT(!aData || aData->mStatus == BufferData::BufferStatus::OMX_CLIENT);
 
-  if (mMediaRawDatas.Length()) {
+  // Don't output sample when flush or shutting down, especially for video
+  // decoded frame. Because video decoded frame has a promise in BufferData
+  // waiting for layer to resolve it via recycle callback on Gonk, if other
+  // module doesn't send it to layer, it will cause a unresolved promise and
+  // waiting for resolve infinitely.
+  if (mFlushing || mShuttingDown) {
+    LOG("mFlush or mShuttingDown, drop data");
+    aData->mStatus = BufferData::BufferStatus::FREE;
     return;
   }
 
-  // When all input buffers are not in omx component, it means all samples have
-  // been fed into OMX component.
-  for (auto buf : mInPortBuffers) {
-    if (buf->mStatus == BufferData::BufferStatus::OMX_COMPONENT) {
-      return;
-    }
-  }
-
-  // When all output buffers are held by component, it means client is waiting for output.
-  for (auto buf : mOutPortBuffers) {
-    if (buf->mStatus != BufferData::BufferStatus::OMX_COMPONENT) {
-      return;
-    }
+  if (aData->mBuffer->nFlags & OMX_BUFFERFLAG_EOS) {
+    // Reach eos, it's an empty data so it doesn't need to output.
+    EndOfStream();
+    aData->mStatus = BufferData::BufferStatus::FREE;
+  } else {
+    Output(aData);
+    FillAndEmptyBuffers();
   }
-
-  LOG("Call InputExhausted()");
-  mCallback->InputExhausted();
 }
 
 void
-OmxDataDecoder::OutputAudio(BufferData* aBufferData)
+OmxDataDecoder::Output(BufferData* aData)
 {
-  MOZ_ASSERT(mOmxTaskQueue->IsCurrentThreadIn());
-  OMX_BUFFERHEADERTYPE* buf = aBufferData->mBuffer;
-  AudioInfo* info = mTrackInfo->GetAsAudioInfo();
-  if (buf->nFilledLen) {
-    uint64_t offset = 0;
-    uint32_t frames = buf->nFilledLen / (2 * info->mChannels);
-    if (aBufferData->mRawData) {
-      offset = aBufferData->mRawData->mOffset;
-    }
-    typedef AudioCompactor::NativeCopy OmxCopy;
-    mAudioCompactor.Push(offset,
-                         buf->nTimeStamp,
-                         info->mRate,
-                         frames,
-                         info->mChannels,
-                         OmxCopy(buf->pBuffer + buf->nOffset,
-                                 buf->nFilledLen,
-                                 info->mChannels));
-    RefPtr<AudioData> audio = mAudioQueue.PopFront();
-    mCallback->Output(audio);
+  if (!mMediaDataHelper) {
+    mMediaDataHelper = new MediaDataHelper(mTrackInfo.get(), mImageContainer, mOmxLayer);
   }
-  aBufferData->mStatus = BufferData::BufferStatus::FREE;
-}
 
-void
-OmxDataDecoder::FillBufferDone(BufferData* aData)
-{
-  MOZ_ASSERT(!aData || aData->mStatus == BufferData::BufferStatus::OMX_CLIENT);
-
-  if (mTrackInfo->IsAudio()) {
-    OutputAudio(aData);
-  } else {
-    MOZ_ASSERT(0);
+  bool isPlatformData = false;
+  RefPtr<MediaData> data = mMediaDataHelper->GetMediaData(aData, isPlatformData);
+  if (!data) {
+    aData->mStatus = BufferData::BufferStatus::FREE;
+    return;
   }
 
-  if (aData->mBuffer->nFlags & OMX_BUFFERFLAG_EOS) {
-    EndOfStream();
-  } else {
-    FillAndEmptyBuffers();
+  if (isPlatformData) {
+    // If the MediaData is platform dependnet data, it's mostly a kind of
+    // limited resource, for example, GraphicBuffer on Gonk. So we use promise
+    // to notify when the resource is free.
+    aData->mStatus = BufferData::BufferStatus::OMX_CLIENT_OUTPUT;
 
-    // If the latest decoded sample's MediaRawData is also the latest input
-    // sample, it means there is no input data in queue and component, calling
-    // CheckIfInputExhausted().
-    if (aData->mRawData == mLatestInputRawData && !mCheckingInputExhausted) {
-      mCheckingInputExhausted = true;
-      nsCOMPtr<nsIRunnable> r =
-        NS_NewRunnableMethod(this, &OmxDataDecoder::CheckIfInputExhausted);
-      mOmxTaskQueue->Dispatch(r.forget());
-    }
+    MOZ_RELEASE_ASSERT(aData->mPromise.IsEmpty());
+    RefPtr<OmxBufferPromise> p = aData->mPromise.Ensure(__func__);
+
+    RefPtr<OmxDataDecoder> self = this;
+    RefPtr<BufferData> buffer = aData;
+    p->Then(mOmxTaskQueue, __func__,
+        [self, buffer] () {
+          MOZ_RELEASE_ASSERT(buffer->mStatus == BufferData::BufferStatus::OMX_CLIENT_OUTPUT);
+          buffer->mStatus = BufferData::BufferStatus::FREE;
+          self->FillAndEmptyBuffers();
+        },
+        [buffer] () {
+          MOZ_RELEASE_ASSERT(buffer->mStatus == BufferData::BufferStatus::OMX_CLIENT_OUTPUT);
+          buffer->mStatus = BufferData::BufferStatus::FREE;
+        });
+  } else {
+    aData->mStatus = BufferData::BufferStatus::FREE;
   }
+
+  mCallback->Output(data);
 }
 
 void
@@ -368,6 +415,30 @@ OmxDataDecoder::EmptyBufferDone(BufferData* aData)
   // Nothing to do when status of input buffer is OMX_CLIENT.
   aData->mStatus = BufferData::BufferStatus::FREE;
   FillAndEmptyBuffers();
+
+  // There is no way to know if component gets enough raw samples to generate
+  // output, especially for video decoding. So here it needs to request raw
+  // samples aggressively.
+  if (!mCheckingInputExhausted && !mMediaRawDatas.Length()) {
+    mCheckingInputExhausted = true;
+
+    RefPtr<OmxDataDecoder> self = this;
+    nsCOMPtr<nsIRunnable> r =
+      NS_NewRunnableFunction([self] () {
+        MOZ_ASSERT(self->mOmxTaskQueue->IsCurrentThreadIn());
+
+        self->mCheckingInputExhausted = false;
+
+        if (self->mMediaRawDatas.Length()) {
+          return;
+        }
+
+        LOGL("Call InputExhausted()");
+        self->mCallback->InputExhausted();
+      });
+
+    mOmxTaskQueue->Dispatch(r.forget());
+  }
 }
 
 void
@@ -389,18 +460,14 @@ OmxDataDecoder::FillAndEmptyBuffers()
   MOZ_ASSERT(mOmxTaskQueue->IsCurrentThreadIn());
   MOZ_ASSERT(mOmxState == OMX_StateExecuting);
 
-  // During the port setting changed, it is forbided to do any buffer operations.
-  if (mPortSettingsChanged != -1 || mShutdown) {
-    return;
-  }
-
-  if (mFlushing) {
+  // During the port setting changed, it is forbidden to do any buffer operation.
+  if (mPortSettingsChanged != -1 || mShuttingDown || mFlushing) {
     return;
   }
 
   // Trigger input port.
   while (!!mMediaRawDatas.Length()) {
-    // input buffer must be usedi by component if there is data available.
+    // input buffer must be used by component if there is data available.
     RefPtr<BufferData> inbuf = FindAvailableBuffer(OMX_DirInput);
     if (!inbuf) {
       LOG("no input buffer!");
@@ -408,10 +475,12 @@ OmxDataDecoder::FillAndEmptyBuffers()
     }
 
     RefPtr<MediaRawData> data = mMediaRawDatas[0];
+    // Buffer size should large enough for raw data.
+    MOZ_RELEASE_ASSERT(inbuf->mBuffer->nAllocLen >= data->Size());
+
     memcpy(inbuf->mBuffer->pBuffer, data->Data(), data->Size());
     inbuf->mBuffer->nFilledLen = data->Size();
     inbuf->mBuffer->nOffset = 0;
-    // TODO: the frame size could larger than buffer size in video case.
     inbuf->mBuffer->nFlags = inbuf->mBuffer->nAllocLen > data->Size() ?
                              OMX_BUFFERFLAG_ENDOFFRAME : 0;
     inbuf->mBuffer->nTimeStamp = data->mTime;
@@ -427,7 +496,6 @@ OmxDataDecoder::FillAndEmptyBuffers()
     mOmxLayer->EmptyBuffer(inbuf)->Then(mOmxTaskQueue, __func__, this,
                                         &OmxDataDecoder::EmptyBufferDone,
                                         &OmxDataDecoder::EmptyBufferFailure);
-    mLatestInputRawData.swap(mMediaRawDatas[0]);
     mMediaRawDatas.RemoveElementAt(0);
   }
 
@@ -490,7 +558,7 @@ OmxDataDecoder::GetBuffers(OMX_DIRTYPE aType)
 void
 OmxDataDecoder::ResolveInitPromise(const char* aMethodName)
 {
-  LOG("Resolved InitPromise");
+  LOG("called from %s", aMethodName);
   RefPtr<OmxDataDecoder> self = this;
   nsCOMPtr<nsIRunnable> r =
     NS_NewRunnableFunction([self, aMethodName] () {
@@ -521,12 +589,9 @@ OmxDataDecoder::OmxStateRunner()
   // TODO: maybe it'd be better to use promise CompletionPromise() to replace
   //       this state machine.
   if (mOmxState == OMX_StateLoaded) {
-    // Config codec parameters by minetype.
-    if (mTrackInfo->IsAudio()) {
-      ConfigAudioCodec();
-    }
+    ConfigCodec();
 
-    // Send OpenMax state commane to OMX_StateIdle.
+    // Send OpenMax state command to OMX_StateIdle.
     RefPtr<OmxDataDecoder> self = this;
     mOmxLayer->SendCommand(OMX_CommandStateSet, OMX_StateIdle, nullptr)
       ->Then(mOmxTaskQueue, __func__,
@@ -562,7 +627,7 @@ OmxDataDecoder::OmxStateRunner()
                self->RejectInitPromise(DecoderFailureReason::INIT_ERROR, __func__);
              });
   } else if (mOmxState == OMX_StateExecuting) {
-    // Config codec once it gets OMX_StateExecuting state.
+    // Configure codec once it gets OMX_StateExecuting state.
     FillCodecConfigDataToOmx();
   } else {
     MOZ_ASSERT(0);
@@ -570,53 +635,45 @@ OmxDataDecoder::OmxStateRunner()
 }
 
 void
-OmxDataDecoder::ConfigAudioCodec()
-{
-  const AudioInfo* audioInfo = mTrackInfo->GetAsAudioInfo();
-  OMX_ERRORTYPE err;
-
-  // TODO: it needs to handle other formats like mp3, amr-nb...etc.
-  if (audioInfo->mMimeType.EqualsLiteral("audio/mp4a-latm")) {
-    OMX_AUDIO_PARAM_AACPROFILETYPE aac_profile;
-    InitOmxParameter(&aac_profile);
-    err = mOmxLayer->GetParameter(OMX_IndexParamAudioAac, &aac_profile, sizeof(aac_profile));
-    CHECK_OMX_ERR(err);
-    aac_profile.nSampleRate = audioInfo->mRate;
-    aac_profile.nChannels = audioInfo->mChannels;
-    aac_profile.eAACProfile = (OMX_AUDIO_AACPROFILETYPE)audioInfo->mProfile;
-    err = mOmxLayer->SetParameter(OMX_IndexParamAudioAac, &aac_profile, sizeof(aac_profile));
-    CHECK_OMX_ERR(err);
-    LOG("Config OMX_IndexParamAudioAac, channel %d, sample rate %d, profile %d",
-        audioInfo->mChannels, audioInfo->mRate, audioInfo->mProfile);
-  }
+OmxDataDecoder::ConfigCodec()
+{
+  OMX_ERRORTYPE err = mOmxLayer->Config();
+  CHECK_OMX_ERR(err);
 }
 
 void
 OmxDataDecoder::FillCodecConfigDataToOmx()
 {
-  // Codec config data should be the first sample running on Omx TaskQueue.
+  // Codec configure data should be the first sample running on Omx TaskQueue.
   MOZ_ASSERT(mOmxTaskQueue->IsCurrentThreadIn());
   MOZ_ASSERT(!mMediaRawDatas.Length());
   MOZ_ASSERT(mOmxState == OMX_StateIdle || mOmxState == OMX_StateExecuting);
 
 
   RefPtr<BufferData> inbuf = FindAvailableBuffer(OMX_DirInput);
+  RefPtr<MediaByteBuffer> csc;
   if (mTrackInfo->IsAudio()) {
-    AudioInfo* audio_info = mTrackInfo->GetAsAudioInfo();
+    csc = mTrackInfo->GetAsAudioInfo()->mCodecSpecificConfig;
+  } else if (mTrackInfo->IsVideo()) {
+    csc = mTrackInfo->GetAsVideoInfo()->mCodecSpecificConfig;
+  }
+
+  MOZ_RELEASE_ASSERT(csc);
+
+  // Some codecs like h264, its codec specific data is at the first packet, not in container.
+  if (csc->Length()) {
     memcpy(inbuf->mBuffer->pBuffer,
-           audio_info->mCodecSpecificConfig->Elements(),
-           audio_info->mCodecSpecificConfig->Length());
-    inbuf->mBuffer->nFilledLen = audio_info->mCodecSpecificConfig->Length();
+           csc->Elements(),
+           csc->Length());
+    inbuf->mBuffer->nFilledLen = csc->Length();
     inbuf->mBuffer->nOffset = 0;
     inbuf->mBuffer->nFlags = (OMX_BUFFERFLAG_ENDOFFRAME | OMX_BUFFERFLAG_CODECCONFIG);
-  } else {
-    MOZ_ASSERT(0);
-  }
 
-  LOG("Feed codec configure data to OMX component");
-  mOmxLayer->EmptyBuffer(inbuf)->Then(mOmxTaskQueue, __func__, this,
-                                      &OmxDataDecoder::EmptyBufferDone,
-                                      &OmxDataDecoder::EmptyBufferFailure);
+    LOG("Feed codec configure data to OMX component");
+    mOmxLayer->EmptyBuffer(inbuf)->Then(mOmxTaskQueue, __func__, this,
+                                        &OmxDataDecoder::EmptyBufferDone,
+                                        &OmxDataDecoder::EmptyBufferFailure);
+  }
 }
 
 bool
@@ -631,20 +688,29 @@ OmxDataDecoder::Event(OMX_EVENTTYPE aEvent, OMX_U32 aData1, OMX_U32 aData2)
   switch (aEvent) {
     case OMX_EventPortSettingsChanged:
     {
-      // According to spec: "To prevent the loss of any input data, the
-      // component issuing the OMX_EventPortSettingsChanged event on its input
-      // port should buffer all input port data that arrives between the
-      // emission of the OMX_EventPortSettingsChanged event and the arrival of
-      // the command to disable the input port."
-      //
-      // So client needs to disable port and reallocate buffers.
-      MOZ_ASSERT(mPortSettingsChanged == -1);
-      mPortSettingsChanged = aData1;
+      // Don't always disable port. See bug 1235340.
+      if (aData2 == 0 ||
+          aData2 == OMX_IndexParamPortDefinition) {
+        // According to spec: "To prevent the loss of any input data, the
+        // component issuing the OMX_EventPortSettingsChanged event on its input
+        // port should buffer all input port data that arrives between the
+        // emission of the OMX_EventPortSettingsChanged event and the arrival of
+        // the command to disable the input port."
+        //
+        // So client needs to disable port and reallocate buffers.
+        MOZ_ASSERT(mPortSettingsChanged == -1);
+        mPortSettingsChanged = aData1;
+      }
       LOG("Got OMX_EventPortSettingsChanged event");
       break;
     }
     default:
     {
+      // Got error during decoding, send msg to MFR skipping to next key frame.
+      if (aEvent == OMX_EventError && mOmxState == OMX_StateExecuting) {
+        NotifyError((OMX_ERRORTYPE)aData1, __func__);
+        return true;
+      }
       LOG("WARNING: got none handle event: %d, aData1: %d, aData2: %d",
           aEvent, aData1, aData2);
       return false;
@@ -654,14 +720,6 @@ OmxDataDecoder::Event(OMX_EVENTTYPE aEvent, OMX_U32 aData1, OMX_U32 aData2)
   return true;
 }
 
-template<class T> void
-OmxDataDecoder::InitOmxParameter(T* aParam)
-{
-  PodZero(aParam);
-  aParam->nSize = sizeof(T);
-  aParam->nVersion.s.nVersionMajor = 1;
-}
-
 bool
 OmxDataDecoder::BuffersCanBeReleased(OMX_DIRTYPE aType)
 {
@@ -781,7 +839,7 @@ OmxDataDecoder::PortSettingsChanged()
       ->CompletionPromise()
       ->Then(mOmxTaskQueue, __func__,
              [self] () {
-               LOG("PortSettingsChanged: port settings changed complete");
+               LOGL("PortSettingsChanged: port settings changed complete");
                // finish port setting changed.
                self->mPortSettingsChanged = -1;
                self->FillAndEmptyBuffers();
@@ -831,7 +889,6 @@ OmxDataDecoder::DoFlush()
 
   // 1. Call OMX command OMX_CommandFlush in Omx TaskQueue.
   // 2. Remove all elements in mMediaRawDatas when flush is completed.
-  RefPtr<OmxDataDecoder> self = this;
   mOmxLayer->SendCommand(OMX_CommandFlush, OMX_ALL, nullptr)
     ->Then(mOmxTaskQueue, __func__, this,
            &OmxDataDecoder::FlushComplete,
@@ -858,4 +915,141 @@ void OmxDataDecoder::FlushFailure(OmxCommandFailureHolder aFailureHolder)
   mMonitor.Notify();
 }
 
+MediaDataHelper::MediaDataHelper(const TrackInfo* aTrackInfo,
+                                 layers::ImageContainer* aImageContainer,
+                                 OmxPromiseLayer* aOmxLayer)
+  : mTrackInfo(aTrackInfo)
+  , mAudioCompactor(mAudioQueue)
+  , mImageContainer(aImageContainer)
+{
+  InitOmxParameter(&mOutputPortDef);
+  mOutputPortDef.nPortIndex = aOmxLayer->OutputPortIndex();
+  aOmxLayer->GetParameter(OMX_IndexParamPortDefinition, &mOutputPortDef, sizeof(mOutputPortDef));
+}
+
+already_AddRefed<MediaData>
+MediaDataHelper::GetMediaData(BufferData* aBufferData, bool& aPlatformDepenentData)
+{
+  aPlatformDepenentData = false;
+  RefPtr<MediaData> data;
+
+  if (mTrackInfo->IsAudio()) {
+    if (!aBufferData->mBuffer->nFilledLen) {
+      return nullptr;
+    }
+    data = CreateAudioData(aBufferData);
+  } else if (mTrackInfo->IsVideo()) {
+    data = aBufferData->GetPlatformMediaData();
+    if (data) {
+      aPlatformDepenentData = true;
+    } else {
+      if (!aBufferData->mBuffer->nFilledLen) {
+        return nullptr;
+      }
+      // Get YUV VideoData, it uses more CPU, in most cases, on software codec.
+      data = CreateYUV420VideoData(aBufferData);
+    }
+
+    // Update video time code, duration... from the raw data.
+    VideoData* video(data->As<VideoData>());
+    if (aBufferData->mRawData) {
+      video->mTime = aBufferData->mRawData->mTime;
+      video->mTimecode = aBufferData->mRawData->mTimecode;
+      video->mOffset = aBufferData->mRawData->mOffset;
+      video->mDuration = aBufferData->mRawData->mDuration;
+      video->mKeyframe = aBufferData->mRawData->mKeyframe;
+    }
+  }
+
+  return data.forget();
+}
+
+already_AddRefed<AudioData>
+MediaDataHelper::CreateAudioData(BufferData* aBufferData)
+{
+  RefPtr<AudioData> audio;
+  OMX_BUFFERHEADERTYPE* buf = aBufferData->mBuffer;
+  const AudioInfo* info = mTrackInfo->GetAsAudioInfo();
+  if (buf->nFilledLen) {
+    uint64_t offset = 0;
+    uint32_t frames = buf->nFilledLen / (2 * info->mChannels);
+    if (aBufferData->mRawData) {
+      offset = aBufferData->mRawData->mOffset;
+    }
+    typedef AudioCompactor::NativeCopy OmxCopy;
+    mAudioCompactor.Push(offset,
+                         buf->nTimeStamp,
+                         info->mRate,
+                         frames,
+                         info->mChannels,
+                         OmxCopy(buf->pBuffer + buf->nOffset,
+                                 buf->nFilledLen,
+                                 info->mChannels));
+    audio = mAudioQueue.PopFront();
+  }
+
+  return audio.forget();
+}
+
+already_AddRefed<VideoData>
+MediaDataHelper::CreateYUV420VideoData(BufferData* aBufferData)
+{
+  uint8_t *yuv420p_buffer = (uint8_t *)aBufferData->mBuffer->pBuffer;
+  int32_t stride = mOutputPortDef.format.video.nStride;
+  int32_t slice_height = mOutputPortDef.format.video.nSliceHeight;
+  int32_t width = mTrackInfo->GetAsVideoInfo()->mImage.width;
+  int32_t height = mTrackInfo->GetAsVideoInfo()->mImage.height;
+
+  // TODO: convert other formats to YUV420.
+  if (mOutputPortDef.format.video.eColorFormat != OMX_COLOR_FormatYUV420Planar) {
+    return nullptr;
+  }
+
+  size_t yuv420p_y_size = stride * slice_height;
+  size_t yuv420p_u_size = ((stride + 1) / 2) * ((slice_height + 1) / 2);
+  uint8_t *yuv420p_y = yuv420p_buffer;
+  uint8_t *yuv420p_u = yuv420p_y + yuv420p_y_size;
+  uint8_t *yuv420p_v = yuv420p_u + yuv420p_u_size;
+
+  VideoData::YCbCrBuffer b;
+  b.mPlanes[0].mData = yuv420p_y;
+  b.mPlanes[0].mWidth = width;
+  b.mPlanes[0].mHeight = height;
+  b.mPlanes[0].mStride = stride;
+  b.mPlanes[0].mOffset = 0;
+  b.mPlanes[0].mSkip = 0;
+
+  b.mPlanes[1].mData = yuv420p_u;
+  b.mPlanes[1].mWidth = (width + 1) / 2;
+  b.mPlanes[1].mHeight = (height + 1) / 2;
+  b.mPlanes[1].mStride = (stride + 1) / 2;
+  b.mPlanes[1].mOffset = 0;
+  b.mPlanes[1].mSkip = 0;
+
+  b.mPlanes[2].mData = yuv420p_v;
+  b.mPlanes[2].mWidth =(width + 1) / 2;
+  b.mPlanes[2].mHeight = (height + 1) / 2;
+  b.mPlanes[2].mStride = (stride + 1) / 2;
+  b.mPlanes[2].mOffset = 0;
+  b.mPlanes[2].mSkip = 0;
+
+  VideoInfo info(*mTrackInfo->GetAsVideoInfo());
+  RefPtr<VideoData> data =
+    VideoData::Create(info,
+                      mImageContainer,
+                      0, // Filled later by caller.
+                      0, // Filled later by caller.
+                      1, // We don't know the duration.
+                      b,
+                      0, // Filled later by caller.
+                      -1,
+                      info.mImage);
+
+  LOG("YUV420 VideoData: disp width %d, height %d, pic width %d, height %d, time %ld",
+      info.mDisplay.width, info.mDisplay.height, info.mImage.width,
+      info.mImage.height, aBufferData->mBuffer->nTimeStamp);
+
+  return data.forget();
+}
+
 }
diff --git a/dom/media/platforms/omx/OmxDataDecoder.h b/dom/media/platforms/omx/OmxDataDecoder.h
index d5fd552..438249e 100644
--- a/dom/media/platforms/omx/OmxDataDecoder.h
+++ b/dom/media/platforms/omx/OmxDataDecoder.h
@@ -8,13 +8,20 @@
 #define OmxDataDecoder_h_
 
 #include "mozilla/Monitor.h"
+
+#include "AudioCompactor.h"
+#include "ImageContainer.h"
+#include "MediaInfo.h"
 #include "PlatformDecoderModule.h"
+
+#include "OMX_Component.h"
+
 #include "OmxPromiseLayer.h"
-#include "MediaInfo.h"
-#include "AudioCompactor.h"
 
 namespace mozilla {
 
+class MediaDataHelper;
+
 typedef OmxPromiseLayer::OmxCommandPromise OmxCommandPromise;
 typedef OmxPromiseLayer::OmxBufferPromise OmxBufferPromise;
 typedef OmxPromiseLayer::OmxBufferFailureHolder OmxBufferFailureHolder;
@@ -27,7 +34,7 @@ typedef OmxPromiseLayer::BUFFERLIST BUFFERLIST;
  *   2. Keeping the buffers between client and component.
  *   3. Manage the OMX state.
  *
- * From the definiton in OpenMax spec. "2.2.1", there are 3 major roles in
+ * From the definition in OpenMax spec. "2.2.1", there are 3 major roles in
  * OpenMax IL.
  *
  * IL client:
@@ -54,7 +61,8 @@ protected:
 
 public:
   OmxDataDecoder(const TrackInfo& aTrackInfo,
-                 MediaDataDecoderCallback* aCallback);
+                 MediaDataDecoderCallback* aCallback,
+                 layers::ImageContainer* aImageContainer);
 
   RefPtr<InitPromise> Init() override;
 
@@ -88,12 +96,13 @@ protected:
 
   void EmptyBufferFailure(OmxBufferFailureHolder aFailureHolder);
 
-  void NotifyError(OMX_ERRORTYPE aError, const char* aLine);
+  void NotifyError(OMX_ERRORTYPE aOmxError,
+                   const char* aLine);
 
-  // Config audio codec.
+  // Configure audio/video codec.
   // Some codec may just ignore this and rely on codec specific data in
   // FillCodecConfigDataToOmx().
-  void ConfigAudioCodec();
+  void ConfigCodec();
 
   // Sending codec specific data to OMX component. OMX component could send a
   // OMX_EventPortSettingsChanged back to client. And then client needs to
@@ -108,12 +117,7 @@ protected:
   // the port format is changed due to different codec specific.
   void PortSettingsChanged();
 
-  void OutputAudio(BufferData* aBufferData);
-
-  // Notify InputExhausted when:
-  //   1. all input buffers are not held by component.
-  //   2. all output buffers are waiting for filling complete.
-  void CheckIfInputExhausted();
+  void Output(BufferData* aData);
 
   // Buffer can be released if its status is not OMX_COMPONENT or
   // OMX_CLIENT_OUTPUT.
@@ -137,8 +141,6 @@ protected:
 
   BufferData* FindAvailableBuffer(OMX_DIRTYPE aType);
 
-  template<class T> void InitOmxParameter(T* aParam);
-
   // aType could be OMX_DirMax for all types.
   RefPtr<OmxPromiseLayer::OmxBufferPromise::AllPromiseType>
   CollectBufferPromises(OMX_DIRTYPE aType);
@@ -150,6 +152,8 @@ protected:
 
   RefPtr<TaskQueue> mReaderTaskQueue;
 
+  RefPtr<layers::ImageContainer> mImageContainer;
+
   WatchManager<OmxDataDecoder> mWatchManager;
 
   // It is accessed in omx TaskQueue.
@@ -163,7 +167,7 @@ protected:
   Atomic<bool> mFlushing;
 
   // It is accessed in Omx/reader TaskQeueu.
-  Atomic<bool> mShutdown;
+  Atomic<bool> mShuttingDown;
 
   // It is accessed in Omx TaskQeueu.
   bool mCheckingInputExhausted;
@@ -182,23 +186,23 @@ protected:
   // It is access in Omx TaskQueue.
   nsTArray<RefPtr<MediaRawData>> mMediaRawDatas;
 
-  // It is access in Omx TaskQueue. The latest input MediaRawData.
-  RefPtr<MediaRawData> mLatestInputRawData;
-
   BUFFERLIST mInPortBuffers;
 
   BUFFERLIST mOutPortBuffers;
 
-  // For audio output.
-  // TODO: because this class is for both video and audio decoding, so there
-  // should be some kind of abstract things to these members.
-  MediaQueue<AudioData> mAudioQueue;
-
-  AudioCompactor mAudioCompactor;
+  RefPtr<MediaDataHelper> mMediaDataHelper;
 
   MediaDataDecoderCallback* mCallback;
 };
 
+template<class T>
+void InitOmxParameter(T* aParam)
+{
+  PodZero(aParam);
+  aParam->nSize = sizeof(T);
+  aParam->nVersion.s.nVersionMajor = 1;
+}
+
 }
 
 #endif /* OmxDataDecoder_h_ */
diff --git a/dom/media/platforms/omx/OmxDecoderModule.cpp b/dom/media/platforms/omx/OmxDecoderModule.cpp
index a0456b7..1d17b88 100644
--- a/dom/media/platforms/omx/OmxDecoderModule.cpp
+++ b/dom/media/platforms/omx/OmxDecoderModule.cpp
@@ -5,7 +5,9 @@
  * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
 
 #include "OmxDecoderModule.h"
+
 #include "OmxDataDecoder.h"
+#include "OmxPlatformLayer.h"
 
 namespace mozilla {
 
@@ -16,7 +18,10 @@ OmxDecoderModule::CreateVideoDecoder(const VideoInfo& aConfig,
                                      FlushableTaskQueue* aVideoTaskQueue,
                                      MediaDataDecoderCallback* aCallback)
 {
-  return nullptr;
+  RefPtr<OmxDataDecoder> decoder = new OmxDataDecoder(aConfig,
+                                                      aCallback,
+                                                      aImageContainer);
+  return decoder.forget();
 }
 
 already_AddRefed<MediaDataDecoder>
@@ -24,26 +29,22 @@ OmxDecoderModule::CreateAudioDecoder(const AudioInfo& aConfig,
                                      FlushableTaskQueue* aAudioTaskQueue,
                                      MediaDataDecoderCallback* aCallback)
 {
-  RefPtr<OmxDataDecoder> decoder = new OmxDataDecoder(aConfig, aCallback);
+  RefPtr<OmxDataDecoder> decoder = new OmxDataDecoder(aConfig,
+                                                      aCallback,
+                                                      nullptr);
   return decoder.forget();
 }
 
-void
-OmxDecoderModule::Init()
-{
-  MOZ_ASSERT(NS_IsMainThread(), "Must be on main thread.");
-}
-
 PlatformDecoderModule::ConversionRequired
 OmxDecoderModule::DecoderNeedsConversion(const TrackInfo& aConfig) const
 {
-  return kNeedNone;
+  return ConversionRequired::kNeedNone;
 }
 
 bool
 OmxDecoderModule::SupportsMimeType(const nsACString& aMimeType) const
 {
-  return aMimeType.EqualsLiteral("audio/mp4a-latm");
+  return OmxPlatformLayer::SupportsMimeType(aMimeType);
 }
 
 }
diff --git a/dom/media/platforms/omx/OmxDecoderModule.h b/dom/media/platforms/omx/OmxDecoderModule.h
index 2a02986..35aab95 100644
--- a/dom/media/platforms/omx/OmxDecoderModule.h
+++ b/dom/media/platforms/omx/OmxDecoderModule.h
@@ -25,8 +25,6 @@ public:
                      FlushableTaskQueue* aAudioTaskQueue,
                      MediaDataDecoderCallback* aCallback) override;
 
-  static void Init();
-
   bool SupportsMimeType(const nsACString& aMimeType) const override;
 
   ConversionRequired DecoderNeedsConversion(const TrackInfo& aConfig) const override;
diff --git a/dom/media/platforms/omx/OmxPlatformLayer.cpp b/dom/media/platforms/omx/OmxPlatformLayer.cpp
new file mode 100644
index 0000000..9ededd8
--- /dev/null
+++ b/dom/media/platforms/omx/OmxPlatformLayer.cpp
@@ -0,0 +1,329 @@
+/* -*- Mode: C++; tab-width: 2; indent-tabs-mode: nil; c-basic-offset: 2 -*- */
+/* vim:set ts=2 sw=2 sts=2 et cindent: */
+/* This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this
+ * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
+
+#include "OmxPlatformLayer.h"
+
+#include "OMX_VideoExt.h" // For VP8.
+
+#if defined(MOZ_WIDGET_GONK) && (ANDROID_VERSION == 20 || ANDROID_VERSION == 19)
+#define OMX_PLATFORM_GONK
+#include "GonkOmxPlatformLayer.h"
+#endif
+
+#include "VPXDecoder.h"
+
+#ifdef LOG
+#undef LOG
+#endif
+
+extern mozilla::LogModule* GetPDMLog();
+
+#define LOG(arg, ...) MOZ_LOG(GetPDMLog(), mozilla::LogLevel::Debug, ("OmxPlatformLayer -- %s: " arg, __func__, ##__VA_ARGS__))
+
+#define RETURN_IF_ERR(err)     \
+  if (err != OMX_ErrorNone) {  \
+    LOG("error: 0x%08x", err); \
+    return err;                \
+  }                            \
+
+// Common OMX decoder configuration code.
+namespace mozilla {
+
+// This helper class encapsulates the details of component parameters setting
+// for different OMX audio & video codecs.
+template<typename ParamType>
+class OmxConfig
+{
+public:
+  virtual ~OmxConfig() {}
+  // Subclasses should implement this method to configure the codec.
+  virtual OMX_ERRORTYPE Apply(OmxPlatformLayer& aOmx, const ParamType& aParam) = 0;
+};
+
+typedef OmxConfig<AudioInfo> OmxAudioConfig;
+typedef OmxConfig<VideoInfo> OmxVideoConfig;
+
+template<typename ConfigType>
+UniquePtr<ConfigType> ConfigForMime(const nsACString&);
+
+static OMX_ERRORTYPE
+ConfigAudioOutputPort(OmxPlatformLayer& aOmx, const AudioInfo& aInfo)
+{
+  OMX_ERRORTYPE err;
+
+  OMX_PARAM_PORTDEFINITIONTYPE def;
+  InitOmxParameter(&def);
+  def.nPortIndex = aOmx.OutputPortIndex();
+  err = aOmx.GetParameter(OMX_IndexParamPortDefinition, &def, sizeof(def));
+  RETURN_IF_ERR(err);
+
+  def.format.audio.eEncoding = OMX_AUDIO_CodingPCM;
+  err = aOmx.SetParameter(OMX_IndexParamPortDefinition, &def, sizeof(def));
+  RETURN_IF_ERR(err);
+
+  OMX_AUDIO_PARAM_PCMMODETYPE pcmParams;
+  InitOmxParameter(&pcmParams);
+  pcmParams.nPortIndex = def.nPortIndex;
+  err = aOmx.GetParameter(OMX_IndexParamAudioPcm, &pcmParams, sizeof(pcmParams));
+  RETURN_IF_ERR(err);
+
+  pcmParams.nChannels = aInfo.mChannels;
+  pcmParams.eNumData = OMX_NumericalDataSigned;
+  pcmParams.bInterleaved = OMX_TRUE;
+  pcmParams.nBitPerSample = 16;
+  pcmParams.nSamplingRate = aInfo.mRate;
+  pcmParams.ePCMMode = OMX_AUDIO_PCMModeLinear;
+  err = aOmx.SetParameter(OMX_IndexParamAudioPcm, &pcmParams, sizeof(pcmParams));
+  RETURN_IF_ERR(err);
+
+  LOG("Config OMX_IndexParamAudioPcm, channel %d, sample rate %d",
+      pcmParams.nChannels, pcmParams.nSamplingRate);
+
+  return OMX_ErrorNone;
+}
+
+class OmxAacConfig : public OmxAudioConfig
+{
+public:
+  OMX_ERRORTYPE Apply(OmxPlatformLayer& aOmx, const AudioInfo& aInfo) override
+  {
+    OMX_ERRORTYPE err;
+
+    OMX_AUDIO_PARAM_AACPROFILETYPE aacProfile;
+    InitOmxParameter(&aacProfile);
+    aacProfile.nPortIndex = aOmx.InputPortIndex();
+    err = aOmx.GetParameter(OMX_IndexParamAudioAac, &aacProfile, sizeof(aacProfile));
+    RETURN_IF_ERR(err);
+
+    aacProfile.nChannels = aInfo.mChannels;
+    aacProfile.nSampleRate = aInfo.mRate;
+    aacProfile.eAACProfile = static_cast<OMX_AUDIO_AACPROFILETYPE>(aInfo.mProfile);
+    err = aOmx.SetParameter(OMX_IndexParamAudioAac, &aacProfile, sizeof(aacProfile));
+    RETURN_IF_ERR(err);
+
+    LOG("Config OMX_IndexParamAudioAac, channel %d, sample rate %d, profile %d",
+        aacProfile.nChannels, aacProfile.nSampleRate, aacProfile.eAACProfile);
+
+    return ConfigAudioOutputPort(aOmx, aInfo);
+  }
+};
+
+class OmxMp3Config : public OmxAudioConfig
+{
+public:
+  OMX_ERRORTYPE Apply(OmxPlatformLayer& aOmx, const AudioInfo& aInfo) override
+  {
+    OMX_ERRORTYPE err;
+
+    OMX_AUDIO_PARAM_MP3TYPE mp3Param;
+    InitOmxParameter(&mp3Param);
+    mp3Param.nPortIndex = aOmx.InputPortIndex();
+    err = aOmx.GetParameter(OMX_IndexParamAudioMp3, &mp3Param, sizeof(mp3Param));
+    RETURN_IF_ERR(err);
+
+    mp3Param.nChannels = aInfo.mChannels;
+    mp3Param.nSampleRate = aInfo.mRate;
+    err = aOmx.SetParameter(OMX_IndexParamAudioMp3, &mp3Param, sizeof(mp3Param));
+    RETURN_IF_ERR(err);
+
+    LOG("Config OMX_IndexParamAudioMp3, channel %d, sample rate %d",
+        mp3Param.nChannels, mp3Param.nSampleRate);
+
+    return ConfigAudioOutputPort(aOmx, aInfo);
+  }
+};
+
+enum OmxAmrSampleRate {
+  kNarrowBand = 8000,
+  kWideBand = 16000,
+};
+
+template <OmxAmrSampleRate R>
+class OmxAmrConfig : public OmxAudioConfig
+{
+public:
+  OMX_ERRORTYPE Apply(OmxPlatformLayer& aOmx, const AudioInfo& aInfo) override
+  {
+    OMX_ERRORTYPE err;
+
+    OMX_AUDIO_PARAM_AMRTYPE def;
+    InitOmxParameter(&def);
+    def.nPortIndex = aOmx.InputPortIndex();
+    err = aOmx.GetParameter(OMX_IndexParamAudioAmr, &def, sizeof(def));
+    RETURN_IF_ERR(err);
+
+    def.eAMRFrameFormat = OMX_AUDIO_AMRFrameFormatFSF;
+    err = aOmx.SetParameter(OMX_IndexParamAudioAmr, &def, sizeof(def));
+    RETURN_IF_ERR(err);
+
+    MOZ_ASSERT(aInfo.mChannels == 1);
+    MOZ_ASSERT(aInfo.mRate == R);
+
+    return ConfigAudioOutputPort(aOmx, aInfo);
+  }
+};
+
+template<>
+UniquePtr<OmxAudioConfig>
+ConfigForMime(const nsACString& aMimeType)
+{
+  UniquePtr<OmxAudioConfig> conf;
+
+  if (OmxPlatformLayer::SupportsMimeType(aMimeType)) {
+    if (aMimeType.EqualsLiteral("audio/mp4a-latm")) {
+      conf.reset(new OmxAacConfig());
+    } else if (aMimeType.EqualsLiteral("audio/mp3") ||
+                aMimeType.EqualsLiteral("audio/mpeg")) {
+      conf.reset(new OmxMp3Config());
+    } else if (aMimeType.EqualsLiteral("audio/3gpp")) {
+      conf.reset(new OmxAmrConfig<OmxAmrSampleRate::kNarrowBand>());
+    } else if (aMimeType.EqualsLiteral("audio/amr-wb")) {
+      conf.reset(new OmxAmrConfig<OmxAmrSampleRate::kWideBand>());
+    }
+  }
+  return Move(conf);
+}
+
+// There should be a better way to calculate it.
+#define MIN_VIDEO_INPUT_BUFFER_SIZE 64 * 1024
+
+class OmxCommonVideoConfig : public OmxVideoConfig
+{
+public:
+  explicit OmxCommonVideoConfig()
+    : OmxVideoConfig()
+  {}
+
+  OMX_ERRORTYPE Apply(OmxPlatformLayer& aOmx, const VideoInfo& aInfo) override
+  {
+    OMX_ERRORTYPE err;
+    OMX_PARAM_PORTDEFINITIONTYPE def;
+
+    // Set up in/out port definition.
+    nsTArray<uint32_t> ports;
+    aOmx.GetPortIndices(ports);
+    for (auto idx : ports) {
+      InitOmxParameter(&def);
+      def.nPortIndex = idx;
+      err = aOmx.GetParameter(OMX_IndexParamPortDefinition, &def, sizeof(def));
+      RETURN_IF_ERR(err);
+
+      def.format.video.nFrameWidth =  aInfo.mDisplay.width;
+      def.format.video.nFrameHeight = aInfo.mDisplay.height;
+      def.format.video.nStride = aInfo.mImage.width;
+      def.format.video.nSliceHeight = aInfo.mImage.height;
+
+      if (def.eDir == OMX_DirInput) {
+        def.format.video.eCompressionFormat = aOmx.CompressionFormat();
+        def.format.video.eColorFormat = OMX_COLOR_FormatUnused;
+        if (def.nBufferSize < MIN_VIDEO_INPUT_BUFFER_SIZE) {
+          def.nBufferSize = aInfo.mImage.width * aInfo.mImage.height;
+          LOG("Change input buffer size to %d", def.nBufferSize);
+        }
+      } else {
+        def.format.video.eCompressionFormat = OMX_VIDEO_CodingUnused;
+      }
+
+      err = aOmx.SetParameter(OMX_IndexParamPortDefinition, &def, sizeof(def));
+    }
+    return err;
+  }
+};
+
+template<>
+UniquePtr<OmxVideoConfig>
+ConfigForMime(const nsACString& aMimeType)
+{
+  UniquePtr<OmxVideoConfig> conf;
+
+  if (OmxPlatformLayer::SupportsMimeType(aMimeType)) {
+    conf.reset(new OmxCommonVideoConfig());
+  }
+  return Move(conf);
+}
+
+OMX_ERRORTYPE
+OmxPlatformLayer::Config()
+{
+  MOZ_ASSERT(mInfo);
+
+  OMX_PORT_PARAM_TYPE portParam;
+  InitOmxParameter(&portParam);
+  if (mInfo->IsAudio()) {
+    GetParameter(OMX_IndexParamAudioInit, &portParam, sizeof(portParam));
+    mStartPortNumber = portParam.nStartPortNumber;
+    UniquePtr<OmxAudioConfig> conf(ConfigForMime<OmxAudioConfig>(mInfo->mMimeType));
+    MOZ_ASSERT(conf.get());
+    return conf->Apply(*this, *(mInfo->GetAsAudioInfo()));
+  } else if (mInfo->IsVideo()) {
+    GetParameter(OMX_IndexParamVideoInit, &portParam, sizeof(portParam));
+    UniquePtr<OmxVideoConfig> conf(ConfigForMime<OmxVideoConfig>(mInfo->mMimeType));
+    MOZ_ASSERT(conf.get());
+    return conf->Apply(*this, *(mInfo->GetAsVideoInfo()));
+  } else {
+    MOZ_ASSERT_UNREACHABLE("non-AV data (text?) is not supported.");
+    return OMX_ErrorNotImplemented;
+  }
+}
+
+OMX_VIDEO_CODINGTYPE
+OmxPlatformLayer::CompressionFormat()
+{
+  MOZ_ASSERT(mInfo);
+
+  if (mInfo->mMimeType.EqualsLiteral("video/avc")) {
+    return OMX_VIDEO_CodingAVC;
+  } else if (mInfo->mMimeType.EqualsLiteral("video/mp4v-es") ||
+       mInfo->mMimeType.EqualsLiteral("video/mp4")) {
+    return OMX_VIDEO_CodingMPEG4;
+  } else if (mInfo->mMimeType.EqualsLiteral("video/3gpp")) {
+    return OMX_VIDEO_CodingH263;
+  } else if (VPXDecoder::IsVPX(mInfo->mMimeType)) {
+    return static_cast<OMX_VIDEO_CODINGTYPE>(OMX_VIDEO_CodingVP8);
+  } else {
+    MOZ_ASSERT_UNREACHABLE("Unsupported compression format");
+    return OMX_VIDEO_CodingUnused;
+  }
+}
+
+// Implementations for different platforms will be defined in their own files.
+#ifdef OMX_PLATFORM_GONK
+
+bool
+OmxPlatformLayer::SupportsMimeType(const nsACString& aMimeType)
+{
+  return GonkOmxPlatformLayer::FindComponents(aMimeType);
+}
+
+OmxPlatformLayer*
+OmxPlatformLayer::Create(OmxDataDecoder* aDataDecoder,
+                         OmxPromiseLayer* aPromiseLayer,
+                         TaskQueue* aTaskQueue,
+                         layers::ImageContainer* aImageContainer)
+{
+  return new GonkOmxPlatformLayer(aDataDecoder, aPromiseLayer, aTaskQueue, aImageContainer);
+}
+
+#else // For platforms without OMX IL support.
+
+bool
+OmxPlatformLayer::SupportsMimeType(const nsACString& aMimeType)
+{
+  return false;
+}
+
+OmxPlatformLayer*
+OmxPlatformLayer::Create(OmxDataDecoder* aDataDecoder,
+                        OmxPromiseLayer* aPromiseLayer,
+                        TaskQueue* aTaskQueue,
+                        layers::ImageContainer* aImageContainer)
+{
+  return nullptr;
+}
+
+#endif
+
+}
diff --git a/dom/media/platforms/omx/OmxPlatformLayer.h b/dom/media/platforms/omx/OmxPlatformLayer.h
index cefdb24..67d9e44 100644
--- a/dom/media/platforms/omx/OmxPlatformLayer.h
+++ b/dom/media/platforms/omx/OmxPlatformLayer.h
@@ -9,18 +9,20 @@
 
 #include "OMX_Core.h"
 #include "OMX_Types.h"
-#include "mozilla/MozPromise.h"
-#include "mozilla/TaskQueue.h"
+
 #include "OmxPromiseLayer.h"
 
+class nsACString;
+
 namespace mozilla {
 
+class TaskQueue;
 class TrackInfo;
 
 /*
  * This class the the abstract layer of the platform OpenMax IL implementation.
  *
- * For some platform like andoird, it exposures its OpenMax IL via IOMX which 
+ * For some platform like andoird, it exposures its OpenMax IL via IOMX which
  * is definitions are different comparing to standard.
  * For other platforms like Raspberry Pi, it will be easy to implement this layer
  * with the standard OpenMax IL api.
@@ -32,6 +34,8 @@ public:
 
   virtual OMX_ERRORTYPE InitOmxToStateLoaded(const TrackInfo* aInfo) = 0;
 
+  OMX_ERRORTYPE Config();
+
   virtual OMX_ERRORTYPE EmptyThisBuffer(BufferData* aData) = 0;
 
   virtual OMX_ERRORTYPE FillThisBuffer(BufferData* aData) = 0;
@@ -60,6 +64,35 @@ public:
   virtual nsresult Shutdown() = 0;
 
   virtual ~OmxPlatformLayer() {}
+
+  // For decoders, input port index is start port number and output port is next.
+  // See OpenMAX IL spec v1.1.2 section 8.6.1 & 8.8.1.
+  OMX_U32 InputPortIndex() { return mStartPortNumber; }
+
+  OMX_U32 OutputPortIndex() { return mStartPortNumber + 1; }
+
+  void GetPortIndices(nsTArray<uint32_t>& aPortIndex) {
+    aPortIndex.AppendElement(InputPortIndex());
+    aPortIndex.AppendElement(OutputPortIndex());
+  }
+
+  virtual OMX_VIDEO_CODINGTYPE CompressionFormat();
+
+  // Check if the platform implementation supports given MIME type.
+  static bool SupportsMimeType(const nsACString& aMimeType);
+
+  // Hide the details of creating implementation objects for different platforms.
+  static OmxPlatformLayer* Create(OmxDataDecoder* aDataDecoder,
+                                  OmxPromiseLayer* aPromiseLayer,
+                                  TaskQueue* aTaskQueue,
+                                  layers::ImageContainer* aImageContainer);
+
+protected:
+  OmxPlatformLayer() : mInfo(nullptr), mStartPortNumber(0) {}
+
+  // The pointee is held by |OmxDataDecoder::mTrackInfo| and will outlive this pointer.
+  const TrackInfo* mInfo;
+  OMX_U32 mStartPortNumber;
 };
 
 }
diff --git a/dom/media/platforms/omx/OmxPromiseLayer.cpp b/dom/media/platforms/omx/OmxPromiseLayer.cpp
index d275c41..b2b5646 100644
--- a/dom/media/platforms/omx/OmxPromiseLayer.cpp
+++ b/dom/media/platforms/omx/OmxPromiseLayer.cpp
@@ -5,37 +5,38 @@
  * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
 
 #include "OmxPromiseLayer.h"
-#include "OmxPlatformLayer.h"
-#include "OmxDataDecoder.h"
 
-#if defined(MOZ_WIDGET_GONK) && ANDROID_VERSION < 21
-#include "GonkOmxPlatformLayer.h"
-#endif
+#include "ImageContainer.h"
+
+#include "OmxDataDecoder.h"
+#include "OmxPlatformLayer.h"
 
-extern mozilla::LogModule* GetPDMLog();
 
 #ifdef LOG
 #undef LOG
 #endif
 
-#define LOG(arg, ...) MOZ_LOG(GetPDMLog(), mozilla::LogLevel::Debug, ("OmxPromiseLayer:: " arg, ##__VA_ARGS__))
+extern mozilla::LogModule* GetPDMLog();
+
+#define LOG(arg, ...) MOZ_LOG(GetPDMLog(), mozilla::LogLevel::Debug, ("OmxPromiseLayer(%p)::%s: " arg, this, __func__, ##__VA_ARGS__))
 
 namespace mozilla {
 
-OmxPromiseLayer::OmxPromiseLayer(TaskQueue* aTaskQueue, OmxDataDecoder* aDataDecoder)
+OmxPromiseLayer::OmxPromiseLayer(TaskQueue* aTaskQueue,
+                                 OmxDataDecoder* aDataDecoder,
+                                 layers::ImageContainer* aImageContainer)
   : mTaskQueue(aTaskQueue)
-  , mFlushPortIndex(0)
 {
-#if defined(MOZ_WIDGET_GONK) && ANDROID_VERSION < 21
-  mPlatformLayer = new GonkOmxPlatformLayer(aDataDecoder, this, aTaskQueue);
-#endif
+  mPlatformLayer = OmxPlatformLayer::Create(aDataDecoder,
+                                            this,
+                                            aTaskQueue,
+                                            aImageContainer);
   MOZ_ASSERT(!!mPlatformLayer);
 }
 
 RefPtr<OmxPromiseLayer::OmxCommandPromise>
-OmxPromiseLayer::Init(TaskQueue* aTaskQueue, const TrackInfo* aInfo)
+OmxPromiseLayer::Init(const TrackInfo* aInfo)
 {
-  mTaskQueue = aTaskQueue;
   MOZ_ASSERT(mTaskQueue->IsCurrentThreadIn());
 
   OMX_ERRORTYPE err = mPlatformLayer->InitOmxToStateLoaded(aInfo);
@@ -55,11 +56,19 @@ OmxPromiseLayer::Init(TaskQueue* aTaskQueue, const TrackInfo* aInfo)
   return OmxCommandPromise::CreateAndReject(failure, __func__);
 }
 
+OMX_ERRORTYPE
+OmxPromiseLayer::Config()
+{
+  MOZ_ASSERT(GetState() == OMX_StateLoaded);
+
+  return mPlatformLayer->Config();
+}
+
 RefPtr<OmxPromiseLayer::OmxBufferPromise>
 OmxPromiseLayer::FillBuffer(BufferData* aData)
 {
   MOZ_ASSERT(mTaskQueue->IsCurrentThreadIn());
-  LOG("FillBuffer: buffer %p", aData->mBuffer);
+  LOG("buffer %p", aData->mBuffer);
 
   RefPtr<OmxBufferPromise> p = aData->mPromise.Ensure(__func__);
 
@@ -80,7 +89,7 @@ RefPtr<OmxPromiseLayer::OmxBufferPromise>
 OmxPromiseLayer::EmptyBuffer(BufferData* aData)
 {
   MOZ_ASSERT(mTaskQueue->IsCurrentThreadIn());
-  LOG("EmptyBuffer: buffer %p, size %d", aData->mBuffer, aData->mBuffer->nFilledLen);
+  LOG("buffer %p, size %d", aData->mBuffer, aData->mBuffer->nFilledLen);
 
   RefPtr<OmxBufferPromise> p = aData->mPromise.Ensure(__func__);
 
@@ -116,7 +125,7 @@ already_AddRefed<MediaRawData>
 OmxPromiseLayer::FindAndRemoveRawData(OMX_TICKS aTimecode)
 {
   for (auto raw : mRawDatas) {
-    if (raw->mTimecode == aTimecode) {
+    if (raw->mTime == aTimecode) {
       mRawDatas.RemoveElement(raw);
       return raw.forget();
     }
@@ -165,15 +174,16 @@ OmxPromiseLayer::FindBufferById(OMX_DIRTYPE aType, BufferData::BufferID aId)
 void
 OmxPromiseLayer::EmptyFillBufferDone(OMX_DIRTYPE aType, BufferData* aData)
 {
-  MOZ_ASSERT(!!aData);
-  LOG("EmptyFillBufferDone: type %d, buffer %p", aType, aData->mBuffer);
   if (aData) {
+    LOG("type %d, buffer %p", aType, aData->mBuffer);
     if (aType == OMX_DirOutput) {
       aData->mRawData = nullptr;
       aData->mRawData = FindAndRemoveRawData(aData->mBuffer->nTimeStamp);
     }
     aData->mStatus = BufferData::BufferStatus::OMX_CLIENT;
     aData->mPromise.Resolve(aData, __func__);
+  } else {
+    LOG("type %d, no buffer", aType);
   }
 }
 
@@ -181,42 +191,54 @@ void
 OmxPromiseLayer::EmptyFillBufferDone(OMX_DIRTYPE aType, BufferData::BufferID aID)
 {
   RefPtr<BufferData> holder = FindAndRemoveBufferHolder(aType, aID);
-  MOZ_ASSERT(!!holder);
-  LOG("EmptyFillBufferDone: type %d, buffer %p", aType, holder->mBuffer);
-  if (holder) {
-    if (aType == OMX_DirOutput) {
-      holder->mRawData = nullptr;
-      holder->mRawData = FindAndRemoveRawData(holder->mBuffer->nTimeStamp);
-    }
-    holder->mStatus = BufferData::BufferStatus::OMX_CLIENT;
-    holder->mPromise.Resolve(holder, __func__);
-  }
+  EmptyFillBufferDone(aType, holder);
 }
 
 RefPtr<OmxPromiseLayer::OmxCommandPromise>
 OmxPromiseLayer::SendCommand(OMX_COMMANDTYPE aCmd, OMX_U32 aParam1, OMX_PTR aCmdData)
 {
-  // No need to issue flush because of buffers are in client already.
-  //
-  // Some components fail to respond flush event when all of buffers are in
-  // client.
   if (aCmd == OMX_CommandFlush) {
-    bool needFlush = false;
-    if ((aParam1 & OMX_DirInput && mInbufferHolders.Length()) ||
-        (aParam1 & OMX_DirOutput && mOutbufferHolders.Length())) {
-      needFlush = true;
-    }
-    if (!needFlush) {
-      LOG("SendCommand: buffers are in client already, no need to flush");
-      mRawDatas.Clear();
-      return OmxCommandPromise::CreateAndResolve(OMX_CommandFlush, __func__);
+    // It doesn't support another flush commands before previous one is completed.
+    MOZ_RELEASE_ASSERT(!mFlushCommands.Length());
+
+    // Some coomponents don't send event with OMX_ALL, they send flush complete
+    // event with input port and another event for output port.
+    // In prupose of better compatibility, we interpret the OMX_ALL to OMX_DirInput
+    // and OMX_DirOutput flush separately.
+    OMX_DIRTYPE types[] = {OMX_DIRTYPE::OMX_DirInput, OMX_DIRTYPE::OMX_DirOutput};
+    for(const auto type : types) {
+      if ((aParam1 == type) || (aParam1 == OMX_ALL)) {
+        mFlushCommands.AppendElement(FlushCommand({type, aCmdData}));
+      }
+
+      if (type == OMX_DirInput) {
+        // Clear all buffered raw data.
+        mRawDatas.Clear();
+      }
     }
-  }
 
-  OMX_ERRORTYPE err = mPlatformLayer->SendCommand(aCmd, aParam1, aCmdData);
-  if (err != OMX_ErrorNone) {
-    OmxCommandFailureHolder failure(OMX_ErrorNotReady, aCmd);
-    return OmxCommandPromise::CreateAndReject(failure, __func__);
+    // Don't overlay more than one flush command, some components can't overlay flush commands.
+    // So here we send another flush after receiving the previous flush completed event.
+    if (mFlushCommands.Length()) {
+      OMX_ERRORTYPE err =
+        mPlatformLayer->SendCommand(OMX_CommandFlush,
+                                    mFlushCommands.ElementAt(0).type,
+                                    mFlushCommands.ElementAt(0).cmd);
+      if (err != OMX_ErrorNone) {
+        OmxCommandFailureHolder failure(OMX_ErrorNotReady, OMX_CommandFlush);
+        return OmxCommandPromise::CreateAndReject(failure, __func__);
+      }
+    } else {
+      LOG("OMX_CommandFlush parameter error");
+      OmxCommandFailureHolder failure(OMX_ErrorNotReady, OMX_CommandFlush);
+      return OmxCommandPromise::CreateAndReject(failure, __func__);
+    }
+  } else {
+    OMX_ERRORTYPE err = mPlatformLayer->SendCommand(aCmd, aParam1, aCmdData);
+    if (err != OMX_ErrorNone) {
+      OmxCommandFailureHolder failure(OMX_ErrorNotReady, aCmd);
+      return OmxCommandPromise::CreateAndReject(failure, __func__);
+    }
   }
 
   RefPtr<OmxCommandPromise> p;
@@ -224,15 +246,12 @@ OmxPromiseLayer::SendCommand(OMX_COMMANDTYPE aCmd, OMX_U32 aParam1, OMX_PTR aCmd
     p = mCommandStatePromise.Ensure(__func__);
   } else if (aCmd == OMX_CommandFlush) {
     p = mFlushPromise.Ensure(__func__);
-    mFlushPortIndex = aParam1;
-    // Clear all buffered raw data.
-    mRawDatas.Clear();
   } else if (aCmd == OMX_CommandPortEnable) {
     p = mPortEnablePromise.Ensure(__func__);
   } else if (aCmd == OMX_CommandPortDisable) {
     p = mPortDisablePromise.Ensure(__func__);
   } else {
-    LOG("SendCommand: error unsupport command");
+    LOG("error unsupport command");
     MOZ_ASSERT(0);
   }
 
@@ -248,8 +267,24 @@ OmxPromiseLayer::Event(OMX_EVENTTYPE aEvent, OMX_U32 aData1, OMX_U32 aData2)
     {
       if (cmd == OMX_CommandStateSet) {
         mCommandStatePromise.Resolve(OMX_CommandStateSet, __func__);
-      } else if (cmd == OMX_CommandFlush && mFlushPortIndex == aData2) {
-        mFlushPromise.Resolve(OMX_CommandFlush, __func__);
+      } else if (cmd == OMX_CommandFlush) {
+        MOZ_RELEASE_ASSERT(mFlushCommands.ElementAt(0).type == aData2);
+        LOG("OMX_CommandFlush completed port type %d", aData2);
+        mFlushCommands.RemoveElementAt(0);
+
+        // Sending next flush command.
+        if (mFlushCommands.Length()) {
+          OMX_ERRORTYPE err =
+            mPlatformLayer->SendCommand(OMX_CommandFlush,
+                                        mFlushCommands.ElementAt(0).type,
+                                        mFlushCommands.ElementAt(0).cmd);
+          if (err != OMX_ErrorNone) {
+            OmxCommandFailureHolder failure(OMX_ErrorNotReady, OMX_CommandFlush);
+            mFlushPromise.Reject(failure, __func__);
+          }
+        } else {
+          mFlushPromise.Resolve(OMX_CommandFlush, __func__);
+        }
       } else if (cmd == OMX_CommandPortDisable) {
         mPortDisablePromise.Resolve(OMX_CommandPortDisable, __func__);
       } else if (cmd == OMX_CommandPortEnable) {
@@ -262,7 +297,7 @@ OmxPromiseLayer::Event(OMX_EVENTTYPE aEvent, OMX_U32 aData1, OMX_U32 aData2)
       if (cmd == OMX_CommandStateSet) {
         OmxCommandFailureHolder failure(OMX_ErrorUndefined, OMX_CommandStateSet);
         mCommandStatePromise.Reject(failure, __func__);
-      } else if (cmd == OMX_CommandFlush && mFlushPortIndex == aData2) {
+      } else if (cmd == OMX_CommandFlush) {
         OmxCommandFailureHolder failure(OMX_ErrorUndefined, OMX_CommandFlush);
         mFlushPromise.Reject(failure, __func__);
       } else if (cmd == OMX_CommandPortDisable) {
@@ -271,6 +306,8 @@ OmxPromiseLayer::Event(OMX_EVENTTYPE aEvent, OMX_U32 aData1, OMX_U32 aData2)
       } else if (cmd == OMX_CommandPortEnable) {
         OmxCommandFailureHolder failure(OMX_ErrorUndefined, OMX_CommandPortEnable);
         mPortEnablePromise.Reject(failure, __func__);
+      } else {
+        return false;
       }
       break;
     }
@@ -322,10 +359,22 @@ OmxPromiseLayer::SetParameter(OMX_INDEXTYPE aParamIndex,
                                       aComponentParameterSize);
 }
 
+OMX_U32
+OmxPromiseLayer::InputPortIndex()
+{
+  return mPlatformLayer->InputPortIndex();
+}
+
+OMX_U32
+OmxPromiseLayer::OutputPortIndex()
+{
+  return mPlatformLayer->OutputPortIndex();
+}
+
 nsresult
 OmxPromiseLayer::Shutdown()
 {
-  LOG("Shutdown");
+  LOG("");
   MOZ_ASSERT(mTaskQueue->IsCurrentThreadIn());
   MOZ_ASSERT(!GetBufferHolders(OMX_DirInput)->Length());
   MOZ_ASSERT(!GetBufferHolders(OMX_DirOutput)->Length());
diff --git a/dom/media/platforms/omx/OmxPromiseLayer.h b/dom/media/platforms/omx/OmxPromiseLayer.h
index aa130d3..ecc6b2a 100644
--- a/dom/media/platforms/omx/OmxPromiseLayer.h
+++ b/dom/media/platforms/omx/OmxPromiseLayer.h
@@ -7,16 +7,25 @@
 #if !defined(OmxPromiseLayer_h_)
 #define OmxPromiseLayer_h_
 
-#include "OMX_Core.h"
-#include "OMX_Types.h"
 #include "mozilla/MozPromise.h"
 #include "mozilla/TaskQueue.h"
+#include "nsAutoPtr.h"
+
+#include "OMX_Core.h"
+#include "OMX_Types.h"
 
 namespace mozilla {
 
-class TrackInfo;
-class OmxPlatformLayer;
+namespace layers
+{
+class ImageContainer;
+}
+
+class MediaData;
+class MediaRawData;
 class OmxDataDecoder;
+class OmxPlatformLayer;
+class TrackInfo;
 
 /* This class acts as a middle layer between OmxDataDecoder and the underlying
  * OmxPlatformLayer.
@@ -38,7 +47,9 @@ protected:
 public:
   NS_INLINE_DECL_THREADSAFE_REFCOUNTING(OmxPromiseLayer)
 
-  OmxPromiseLayer(TaskQueue* aTaskQueue, OmxDataDecoder* aDataDecoder);
+  OmxPromiseLayer(TaskQueue* aTaskQueue,
+                  OmxDataDecoder* aDataDecoder,
+                  layers::ImageContainer* aImageContainer);
 
   class BufferData;
 
@@ -74,7 +85,9 @@ public:
   typedef MozPromise<uint32_t, bool, /* IsExclusive = */ true> OmxPortConfigPromise;
 
   // TODO: maybe a generic promise is good enough for this case?
-  RefPtr<OmxCommandPromise> Init(TaskQueue* aQueue, const TrackInfo* aInfo);
+  RefPtr<OmxCommandPromise> Init(const TrackInfo* aInfo);
+
+  OMX_ERRORTYPE Config();
 
   RefPtr<OmxBufferPromise> FillBuffer(BufferData* aData);
 
@@ -98,6 +111,10 @@ public:
                              OMX_PTR aComponentParameterStructure,
                              OMX_U32 aComponentParameterSize);
 
+  OMX_U32 InputPortIndex();
+
+  OMX_U32 OutputPortIndex();
+
   nsresult Shutdown();
 
   // BufferData maintains the status of OMX buffer (OMX_BUFFERHEADERTYPE).
@@ -125,6 +142,15 @@ public:
       return mBuffer;
     }
 
+    // Return the platform dependent MediaData().
+    // For example, it returns the MediaData with Gralloc texture.
+    // If it returns nullptr, then caller uses the normal way to
+    // create MediaData().
+    virtual already_AddRefed<MediaData> GetPlatformMediaData()
+    {
+      return nullptr;
+    }
+
     // The buffer could be used by several objects. And only one object owns the
     // buffer the same time.
     //   FREE:
@@ -162,7 +188,7 @@ public:
     // records of the original data from demuxer, like duration, stream offset...etc.
     RefPtr<MediaRawData> mRawData;
 
-    // Because OMX buffer works acorssing threads, so it uses a promise
+    // Because OMX buffer works across threads, so it uses a promise
     // for each buffer when the buffer is used by Omx component.
     MozPromiseHolder<OmxBufferPromise> mPromise;
     BufferStatus mStatus;
@@ -179,10 +205,15 @@ public:
   already_AddRefed<BufferData>
   FindAndRemoveBufferHolder(OMX_DIRTYPE aType, BufferData::BufferID aId);
 
-  // Return truen if event is handled.
+  // Return true if event is handled.
   bool Event(OMX_EVENTTYPE aEvent, OMX_U32 aData1, OMX_U32 aData2);
 
 protected:
+  struct FlushCommand {
+    OMX_DIRTYPE type;
+    OMX_PTR cmd;
+  };
+
   BUFFERLIST* GetBufferHolders(OMX_DIRTYPE aType);
 
   already_AddRefed<MediaRawData> FindAndRemoveRawData(OMX_TICKS aTimecode);
@@ -197,15 +228,15 @@ protected:
 
   MozPromiseHolder<OmxCommandPromise> mFlushPromise;
 
-  OMX_U32 mFlushPortIndex;
+  nsTArray<FlushCommand> mFlushCommands;
 
   nsAutoPtr<OmxPlatformLayer> mPlatformLayer;
 
 private:
   // Elements are added to holders when FillBuffer() or FillBuffer(). And
-  // removing elelments when the promise is resolved. Buffers in these lists
+  // removing element when the promise is resolved. Buffers in these lists
   // should NOT be used by other component; for example, output it to audio
-  // output. These list should be empty when engine is about to shutdown.
+  // output. These lists should be empty when engine is about to shutdown.
   //
   // Note:
   //      There bufferlist should not be used by other class directly.
diff --git a/dom/media/platforms/omx/moz.build b/dom/media/platforms/omx/moz.build
index 3db29b1..9ad0833e 100644
--- a/dom/media/platforms/omx/moz.build
+++ b/dom/media/platforms/omx/moz.build
@@ -1,4 +1,4 @@
-# -*- Mode: python; c-basic-offset: 4; indent-tabs-mode: nil; tab-width: 40 -*-
+# -*- Mode: python; indent-tabs-mode: nil; tab-width: 40 -*-
 # vim: set filetype=python:
 # This Source Code Form is subject to the terms of the Mozilla Public
 # License, v. 2.0. If a copy of the MPL was not distributed with this
@@ -11,6 +11,7 @@ EXPORTS += [
 UNIFIED_SOURCES += [
     'OmxDataDecoder.cpp',
     'OmxDecoderModule.cpp',
+    'OmxPlatformLayer.cpp',
     'OmxPromiseLayer.cpp',
 ]
 
@@ -44,3 +45,6 @@ if CONFIG['MOZ_WIDGET_TOOLKIT'] == 'gonk' and (CONFIG['ANDROID_VERSION'] == '19'
     ]
 
 FINAL_LIBRARY = 'xul'
+
+if CONFIG['GNU_CXX']:
+    CXXFLAGS += ['-Wno-error=shadow']
-- 
1.9.1

